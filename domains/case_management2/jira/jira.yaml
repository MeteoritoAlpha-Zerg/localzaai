name: jira
description: Create an API integration with JIRA per its API specification
category: Project Management
stages:
- provenance:
    source_file: domains/case_management/jira/jira.yaml
    domain: case_management
    manifest: jira
    referenced_files:
      '!python/program:stages/1-verify_credentials.py':
        directive: '!python/program'
        original_path: stages/1-verify_credentials.py
        function_name: null
        resolved_path: domains/case_management/jira/stages/1-verify_credentials.py
  name: verify credentials
  type: stagetype.before
  description: verifies the credentials as provided to zerg for the connector generation
  preconditions: None
  postconditions: Credentials are verified and valid
  code_to_run: null
  code: "import os\nimport sys\nimport json\nimport logging\nimport requests\nfrom\
    \ requests.auth import HTTPBasicAuth\nimport base64\n\n# Setup logging\nlogging.basicConfig(\n\
    \    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s -\
    \ %(message)s'\n)\nL = logging.getLogger(__name__)\n\ndef verify_jira_credentials():\n\
    \    \"\"\"\n    Verify JIRA credentials by attempting to authenticate and access\
    \ JIRA API.\n    \n    Environment variables required:\n    - jira_url: Base URL\
    \ of the JIRA instance\n    - jira_email: Email address for authentication\n \
    \   - jira_api_token: API Token for authentication\n    - jira_api_request_timeout:\
    \ Request timeout in seconds (optional, defaults to 30)\n    - jira_api_max_retries:\
    \ Max retries for API requests (optional, defaults to 3)\n    \n    Returns:\n\
    \    - True if credentials are valid and can access JIRA API\n    - False otherwise\n\
    \    \"\"\"\n    \n    # Get environment variables\n    jira_url = os.environ.get('JIRA_URL')\n\
    \    jira_email = os.environ.get('JIRA_EMAIL')\n    jira_api_token = os.environ.get('JIRA_API_TOKEN')\n\
    \    jira_api_request_timeout = int(os.environ.get('JIRA_API_REQUEST_TIMEOUT',\
    \ 30))\n    jira_api_max_retries = int(os.environ.get('JIRA_API_MAX_RETRIES',\
    \ 3))\n    \n    L.info(\"Retrieved environment variables\")\n    L.info(f\"Using\
    \ JIRA URL: {jira_url}\")\n    L.info(f\"Using email: {jira_email}\")\n    L.info(f\"\
    Request timeout: {jira_api_request_timeout}s\")\n    L.info(f\"Max retries: {jira_api_max_retries}\"\
    )\n    \n    # Validate that all necessary environment variables are set\n   \
    \ missing_vars = []\n    if not jira_url:\n        missing_vars.append('JIRA_URL')\n\
    \    if not jira_email:\n        missing_vars.append('JIRA_EMAIL')\n    if not\
    \ jira_api_token:\n        missing_vars.append('JIRA_API_TOKEN')\n    \n    if\
    \ missing_vars:\n        L.error(f\"Missing required environment variables: {',\
    \ '.join(missing_vars)}\")\n        print(f\"Error: Missing required environment\
    \ variables: {', '.join(missing_vars)}\")\n        return False\n    \n    # Ensure\
    \ the URL has the proper format\n    if not jira_url.startswith(('http://', 'https://')):\n\
    \        L.error(f\"Invalid JIRA URL format: {jira_url}. Must start with http://\
    \ or https://\")\n        return False\n    \n    # Remove trailing slash if present\n\
    \    jira_url = jira_url.rstrip('/')\n    \n    try:\n        # Test JIRA API\
    \ with authentication\n        L.info(f\"Attempting to connect to JIRA instance\
    \ at: {jira_url}\")\n        \n        # Create authentication\n        auth =\
    \ HTTPBasicAuth(jira_email, jira_api_token)\n        \n        # Test endpoint:\
    \ Get server info (lightweight call)\n        test_url = f\"{jira_url}/rest/api/2/serverInfo\"\
    \n        \n        for attempt in range(jira_api_max_retries):\n            try:\n\
    \                L.info(f\"Authentication attempt {attempt + 1}/{jira_api_max_retries}\"\
    )\n                \n                response = requests.get(\n              \
    \      test_url,\n                    auth=auth,\n                    timeout=jira_api_request_timeout,\n\
    \                    headers={\n                        'Accept': 'application/json',\n\
    \                        'Content-Type': 'application/json'\n                \
    \    }\n                )\n                \n                if response.status_code\
    \ == 200:\n                    server_info = response.json()\n               \
    \     L.info(f\"Successfully authenticated with JIRA\")\n                    L.info(f\"\
    Server info: Version {server_info.get('version', 'Unknown')}, \"\n           \
    \                f\"Build {server_info.get('buildNumber', 'Unknown')}\")\n   \
    \                 \n                    # Test another endpoint to ensure proper\
    \ access: Get current user\n                    user_url = f\"{jira_url}/rest/api/2/myself\"\
    \n                    user_response = requests.get(\n                        user_url,\n\
    \                        auth=auth,\n                        timeout=jira_api_request_timeout,\n\
    \                        headers={\n                            'Accept': 'application/json',\n\
    \                            'Content-Type': 'application/json'\n            \
    \            }\n                    )\n                    \n                \
    \    if user_response.status_code == 200:\n                        user_info =\
    \ user_response.json()\n                        L.info(f\"Authenticated as user:\
    \ {user_info.get('displayName', 'Unknown')} \"\n                             \
    \  f\"({user_info.get('emailAddress', 'Unknown')})\")\n                      \
    \  \n                        # Test permissions by trying to get projects (minimal\
    \ request)\n                        projects_url = f\"{jira_url}/rest/api/2/project\"\
    \n                        projects_response = requests.get(\n                \
    \            projects_url,\n                            auth=auth,\n         \
    \                   timeout=jira_api_request_timeout,\n                      \
    \      headers={\n                                'Accept': 'application/json',\n\
    \                                'Content-Type': 'application/json'\n        \
    \                    },\n                            params={'maxResults': 1}\
    \  # Just test access, don't need all projects\n                        )\n  \
    \                      \n                        if projects_response.status_code\
    \ == 200:\n                            L.info(\"Successfully verified project\
    \ access permissions\")\n                            L.info(\"All credential verification\
    \ tests passed\")\n                            return True\n                 \
    \       else:\n                            L.error(f\"Failed to access projects\
    \ endpoint. Status: {projects_response.status_code}, \"\n                    \
    \               f\"Response: {projects_response.text}\")\n                   \
    \         return False\n                    else:\n                        L.error(f\"\
    Failed to get current user info. Status: {user_response.status_code}, \"\n   \
    \                            f\"Response: {user_response.text}\")\n          \
    \              return False\n                        \n                elif response.status_code\
    \ == 401:\n                    L.error(\"Authentication failed - Invalid credentials\"\
    )\n                    return False\n                elif response.status_code\
    \ == 403:\n                    L.error(\"Authentication failed - Access forbidden\
    \ (check permissions)\")\n                    return False\n                elif\
    \ response.status_code == 404:\n                    L.error(\"JIRA API endpoint\
    \ not found - Check JIRA URL\")\n                    return False\n          \
    \      else:\n                    L.warning(f\"Attempt {attempt + 1} failed with\
    \ status {response.status_code}: {response.text}\")\n                    if attempt\
    \ == jira_api_max_retries - 1:\n                        L.error(f\"All {jira_api_max_retries}\
    \ attempts failed\")\n                        return False\n                 \
    \   \n            except requests.exceptions.Timeout:\n                L.warning(f\"\
    Attempt {attempt + 1} timed out after {jira_api_request_timeout} seconds\")\n\
    \                if attempt == jira_api_max_retries - 1:\n                   \
    \ L.error(f\"All {jira_api_max_retries} attempts timed out\")\n              \
    \      return False\n            except requests.exceptions.ConnectionError as\
    \ e:\n                L.warning(f\"Attempt {attempt + 1} failed with connection\
    \ error: {e}\")\n                if attempt == jira_api_max_retries - 1:\n   \
    \                 L.error(f\"All {jira_api_max_retries} attempts failed with connection\
    \ errors\")\n                    return False\n            except requests.exceptions.RequestException\
    \ as e:\n                L.error(f\"Request exception on attempt {attempt + 1}:\
    \ {e}\")\n                if attempt == jira_api_max_retries - 1:\n          \
    \          return False\n        \n        return False\n        \n    except\
    \ Exception as e:\n        L.error(f\"Unexpected exception during credential verification:\
    \ {e}\")\n        return False\n\ndef test_jira_api_endpoints():\n    \"\"\"\n\
    \    Test additional JIRA API endpoints to ensure comprehensive access.\n    \n\
    \    Returns:\n    - True if all endpoint tests pass\n    - False otherwise\n\
    \    \"\"\"\n    \n    # Get environment variables\n    jira_url = os.environ.get('JIRA_URL').rstrip('/')\n\
    \    jira_email = os.environ.get('JIRA_EMAIL')\n    jira_api_token = os.environ.get('JIRA_API_TOKEN')\n\
    \    jira_api_request_timeout = int(os.environ.get('JIRA_API_REQUEST_TIMEOUT',\
    \ 30))\n    \n    auth = HTTPBasicAuth(jira_email, jira_api_token)\n    \n   \
    \ # Test endpoints that will be used by the connector\n    test_endpoints = [\n\
    \        {\n            'name': 'Projects List',\n            'url': f\"{jira_url}/rest/api/2/project\"\
    ,\n            'params': {'maxResults': 5}\n        },\n        {\n          \
    \  'name': 'Issue Search',\n            'url': f\"{jira_url}/rest/api/2/search\"\
    ,\n            'params': {'maxResults': 1, 'jql': 'order by created DESC'}\n \
    \       }\n    ]\n    \n    L.info(\"Testing additional JIRA API endpoints...\"\
    )\n    \n    for endpoint in test_endpoints:\n        try:\n            L.info(f\"\
    Testing {endpoint['name']} endpoint...\")\n            \n            response\
    \ = requests.get(\n                endpoint['url'],\n                auth=auth,\n\
    \                timeout=jira_api_request_timeout,\n                headers={\n\
    \                    'Accept': 'application/json',\n                    'Content-Type':\
    \ 'application/json'\n                },\n                params=endpoint.get('params',\
    \ {})\n            )\n            \n            if response.status_code == 200:\n\
    \                L.info(f\"\u2705 {endpoint['name']} endpoint test passed\")\n\
    \            else:\n                L.warning(f\"\u26A0\uFE0F  {endpoint['name']}\
    \ endpoint returned status {response.status_code}\")\n                L.warning(f\"\
    Response: {response.text}\")\n                \n        except Exception as e:\n\
    \            L.error(f\"\u274C {endpoint['name']} endpoint test failed: {e}\"\
    )\n            return False\n    \n    L.info(\"All endpoint tests completed\"\
    )\n    return True\n\ndef main():\n    L.info(\"Starting JIRA credential verification\"\
    )\n    \n    if len(sys.argv) > 1 and sys.argv[1] == '--set-env':\n        L.info(\"\
    Using manual credential input mode\")\n        \n        if not os.environ.get('JIRA_URL'):\n\
    \            os.environ['JIRA_URL'] = input(\"Enter JIRA URL (e.g., https://your-domain.atlassian.net):\
    \ \")\n        if not os.environ.get('JIRA_EMAIL'):\n            os.environ['JIRA_EMAIL']\
    \ = input(\"Enter JIRA email address: \")\n        if not os.environ.get('JIRA_API_TOKEN'):\n\
    \            os.environ['JIRA_API_TOKEN'] = input(\"Enter JIRA API token: \")\n\
    \        if not os.environ.get('JIRA_API_REQUEST_TIMEOUT'):\n            timeout\
    \ = input(\"Enter request timeout in seconds (default 30): \")\n            os.environ['JIRA_API_REQUEST_TIMEOUT']\
    \ = timeout if timeout else '30'\n        if not os.environ.get('JIRA_API_MAX_RETRIES'):\n\
    \            retries = input(\"Enter max retries (default 3): \")\n          \
    \  os.environ['JIRA_API_MAX_RETRIES'] = retries if retries else '3'\n    else:\n\
    \        L.info(\"Using environment variables for credentials\")\n    \n    #\
    \ Basic credential verification\n    L.info(\"\\n=== Basic Credential Verification\
    \ ===\")\n    success = verify_jira_credentials()\n    \n    if not success:\n\
    \        L.error(\"\u274C Basic credential verification failed\")\n        return\
    \ 1\n    \n    # Extended endpoint testing\n    L.info(\"\\n=== Extended API Endpoint\
    \ Testing ===\")\n    endpoint_success = test_jira_api_endpoints()\n    \n   \
    \ if success and endpoint_success:\n        L.info(\"\u2705 All JIRA credential\
    \ verification tests completed successfully\")\n        L.info(\"Credentials are\
    \ verified and valid\")\n        return 0\n    elif success:\n        L.warning(\"\
    \u26A0\uFE0F  Basic verification passed but some endpoint tests had issues\")\n\
    \        L.info(\"Credentials are verified and valid (with warnings)\")\n    \
    \    return 0\n    else:\n        L.error(\"\u274C Credential verification failed\"\
    )\n        return 1\n\nif __name__ == \"__main__\":\n    sys.exit(main())"
- provenance:
    source_file: domains/case_management/jira/jira.yaml
    domain: case_management
    manifest: jira
    referenced_files:
      '!python/program:stages/2-stage-data.py':
        directive: '!python/program'
        original_path: stages/2-stage-data.py
        function_name: null
        resolved_path: domains/case_management/jira/stages/2-stage-data.py
  name: stage data
  type: stagetype.before
  description: verifies that data instance has valid data in it and if not populates
    / stages the data in the target instance
  preconditions: valid credentials per the verify credential stage
  postconditions: Target instance is valid, has valid data per the intents of this
    specification
  code_to_run: null
  code: "import os\nimport sys\nimport json\nimport logging\nimport requests\nfrom\
    \ requests.auth import HTTPBasicAuth\nimport random\nimport time\nfrom datetime\
    \ import datetime, timedelta\n\n# Setup logging\nlogging.basicConfig(\n    level=logging.INFO,\n\
    \    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\nL = logging.getLogger(__name__)\n\
    \ndef connect_to_jira():\n    \"\"\"\n    Connect to JIRA using environment variables.\n\
    \    \n    Returns:\n    - tuple: (jira_url, auth, timeout) if successful\n  \
    \  - None if connection fails\n    \"\"\"\n    jira_url = os.environ.get('JIRA_URL')\n\
    \    jira_email = os.environ.get('JIRA_EMAIL')\n    jira_api_token = os.environ.get('JIRA_API_TOKEN')\n\
    \    jira_api_request_timeout = int(os.environ.get('JIRA_API_REQUEST_TIMEOUT',\
    \ 30))\n    \n    # Check required environment variables\n    missing_vars = []\n\
    \    if not jira_url:\n        missing_vars.append('JIRA_URL')\n    if not jira_email:\n\
    \        missing_vars.append('JIRA_EMAIL')\n    if not jira_api_token:\n     \
    \   missing_vars.append('JIRA_API_TOKEN')\n    \n    if missing_vars:\n      \
    \  L.error(f\"Missing required environment variables: {', '.join(missing_vars)}\"\
    )\n        raise ValueError(f\"Missing required environment variables: {', '.join(missing_vars)}\"\
    )\n    \n    # Remove trailing slash and create auth\n    jira_url = jira_url.rstrip('/')\n\
    \    auth = HTTPBasicAuth(jira_email, jira_api_token)\n    \n    L.info(f\"Connected\
    \ to JIRA at {jira_url}\")\n    return jira_url, auth, jira_api_request_timeout\n\
    \ndef check_existing_data(jira_url, auth, timeout):\n    \"\"\"\n    Check if\
    \ JIRA instance has sufficient data for connector testing.\n    \n    Args:\n\
    \        jira_url (str): Base JIRA URL\n        auth (HTTPBasicAuth): Authentication\
    \ object\n        timeout (int): Request timeout\n        \n    Returns:\n   \
    \     dict: Information about existing projects and issues\n    \"\"\"\n    L.info(\"\
    Checking existing data in JIRA instance...\")\n    \n    try:\n        # Get all\
    \ projects\n        projects_url = f\"{jira_url}/rest/api/2/project\"\n      \
    \  projects_response = requests.get(\n            projects_url,\n            auth=auth,\n\
    \            timeout=timeout,\n            headers={'Accept': 'application/json',\
    \ 'Content-Type': 'application/json'}\n        )\n        \n        if projects_response.status_code\
    \ != 200:\n            L.error(f\"Failed to retrieve projects: {projects_response.status_code}\
    \ - {projects_response.text}\")\n            return None\n        \n        projects\
    \ = projects_response.json()\n        L.info(f\"Found {len(projects)} existing\
    \ projects\")\n        \n        # Check issues in each project\n        project_data\
    \ = {}\n        total_issues = 0\n        \n        for project in projects:\n\
    \            project_key = project['key']\n            project_name = project['name']\n\
    \            \n            # Get issue count for this project\n            search_url\
    \ = f\"{jira_url}/rest/api/2/search\"\n            search_params = {\n       \
    \         'jql': f'project = {project_key}',\n                'maxResults': 0\
    \  # We only want the total count\n            }\n            \n            search_response\
    \ = requests.get(\n                search_url,\n                auth=auth,\n \
    \               timeout=timeout,\n                headers={'Accept': 'application/json',\
    \ 'Content-Type': 'application/json'},\n                params=search_params\n\
    \            )\n            \n            if search_response.status_code == 200:\n\
    \                search_result = search_response.json()\n                issue_count\
    \ = search_result.get('total', 0)\n                total_issues += issue_count\n\
    \                \n                project_data[project_key] = {\n           \
    \         'name': project_name,\n                    'key': project_key,\n   \
    \                 'id': project.get('id'),\n                    'description':\
    \ project.get('description', ''),\n                    'issue_count': issue_count,\n\
    \                    'lead': project.get('lead', {}).get('displayName', 'Unknown')\n\
    \                }\n                \n                L.info(f\"Project {project_key}\
    \ ({project_name}): {issue_count} issues\")\n            else:\n             \
    \   L.warning(f\"Could not get issue count for project {project_key}\")\n    \
    \            project_data[project_key] = {\n                    'name': project_name,\n\
    \                    'key': project_key,\n                    'id': project.get('id'),\n\
    \                    'description': project.get('description', ''),\n        \
    \            'issue_count': 0,\n                    'lead': project.get('lead',\
    \ {}).get('displayName', 'Unknown')\n                }\n        \n        L.info(f\"\
    Total issues across all projects: {total_issues}\")\n        \n        return\
    \ {\n            'projects': project_data,\n            'total_projects': len(projects),\n\
    \            'total_issues': total_issues\n        }\n        \n    except Exception\
    \ as e:\n        L.error(f\"Error checking existing data: {e}\")\n        return\
    \ None\n\ndef is_data_sufficient(existing_data, min_projects=2, min_issues_per_project=3,\
    \ min_total_issues=5):\n    \"\"\"\n    Determine if existing data is sufficient\
    \ for connector testing.\n    \n    Args:\n        existing_data (dict): Data\
    \ from check_existing_data()\n        min_projects (int): Minimum number of projects\
    \ required\n        min_issues_per_project (int): Minimum issues per project\n\
    \        min_total_issues (int): Minimum total issues across all projects\n  \
    \      \n    Returns:\n        tuple: (is_sufficient, missing_requirements)\n\
    \    \"\"\"\n    if not existing_data:\n        return False, [\"Could not retrieve\
    \ existing data\"]\n    \n    missing_requirements = []\n    \n    # Check minimum\
    \ projects\n    if existing_data['total_projects'] < min_projects:\n        missing_requirements.append(f\"\
    Need at least {min_projects} projects (found {existing_data['total_projects']})\"\
    )\n    \n    # Check minimum total issues\n    if existing_data['total_issues']\
    \ < min_total_issues:\n        missing_requirements.append(f\"Need at least {min_total_issues}\
    \ total issues (found {existing_data['total_issues']})\")\n    \n    # Check if\
    \ at least one project has sufficient issues\n    projects_with_sufficient_issues\
    \ = 0\n    for project_key, project_info in existing_data['projects'].items():\n\
    \        if project_info['issue_count'] >= min_issues_per_project:\n         \
    \   projects_with_sufficient_issues += 1\n    \n    if projects_with_sufficient_issues\
    \ == 0:\n        missing_requirements.append(f\"Need at least one project with\
    \ {min_issues_per_project}+ issues\")\n    \n    is_sufficient = len(missing_requirements)\
    \ == 0\n    \n    if is_sufficient:\n        L.info(\"\u2705 Existing data is\
    \ sufficient for connector testing\")\n    else:\n        L.info(\"\u274C Existing\
    \ data is insufficient:\")\n        for req in missing_requirements:\n       \
    \     L.info(f\"  - {req}\")\n    \n    return is_sufficient, missing_requirements\n\
    \ndef create_test_project(jira_url, auth, timeout, project_key=None, project_name=None):\n\
    \    \"\"\"\n    Create a test project in JIRA.\n    \n    Args:\n        jira_url\
    \ (str): Base JIRA URL\n        auth (HTTPBasicAuth): Authentication object\n\
    \        timeout (int): Request timeout\n        project_key (str): Optional project\
    \ key\n        project_name (str): Optional project name\n        \n    Returns:\n\
    \        dict: Created project information or None if failed\n    \"\"\"\n   \
    \ if not project_key:\n        timestamp = datetime.now().strftime('%Y%m%d%H%M%S')\n\
    \        project_key = f\"TEST{timestamp[-6:]}\"  # Use last 6 digits to keep\
    \ it short\n    \n    if not project_name:\n        project_name = f\"Test Project\
    \ {datetime.now().strftime('%Y-%m-%d %H:%M')}\"\n    \n    L.info(f\"Creating\
    \ test project: {project_name} ({project_key})\")\n    \n    try:\n        # First,\
    \ get available project types\n        project_types_url = f\"{jira_url}/rest/api/2/project/type\"\
    \n        types_response = requests.get(\n            project_types_url,\n   \
    \         auth=auth,\n            timeout=timeout,\n            headers={'Accept':\
    \ 'application/json', 'Content-Type': 'application/json'}\n        )\n       \
    \ \n        project_type_key = \"software\"  # Default\n        if types_response.status_code\
    \ == 200:\n            project_types = types_response.json()\n            if project_types:\n\
    \                # Use the first available project type\n                project_type_key\
    \ = project_types[0].get('key', 'software')\n                L.info(f\"Using project\
    \ type: {project_type_key}\")\n        \n        # Get current user to set as\
    \ project lead\n        user_url = f\"{jira_url}/rest/api/2/myself\"\n       \
    \ user_response = requests.get(\n            user_url,\n            auth=auth,\n\
    \            timeout=timeout,\n            headers={'Accept': 'application/json',\
    \ 'Content-Type': 'application/json'}\n        )\n        \n        lead_account_id\
    \ = None\n        if user_response.status_code == 200:\n            user_info\
    \ = user_response.json()\n            lead_account_id = user_info.get('accountId')\n\
    \            L.info(f\"Using current user as project lead: {user_info.get('displayName')}\"\
    )\n        \n        # Create project\n        create_url = f\"{jira_url}/rest/api/2/project\"\
    \n        project_data = {\n            \"key\": project_key,\n            \"\
    name\": project_name,\n            \"projectTypeKey\": project_type_key,\n   \
    \         \"description\": f\"Test project created for JIRA connector testing\
    \ on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n        }\n        \n \
    \       if lead_account_id:\n            project_data[\"leadAccountId\"] = lead_account_id\n\
    \        \n        create_response = requests.post(\n            create_url,\n\
    \            auth=auth,\n            timeout=timeout,\n            headers={'Accept':\
    \ 'application/json', 'Content-Type': 'application/json'},\n            json=project_data\n\
    \        )\n        \n        if create_response.status_code in [200, 201]:\n\
    \            project_info = create_response.json()\n            L.info(f\"\u2705\
    \ Successfully created project: {project_name} ({project_key})\")\n          \
    \  return {\n                'key': project_key,\n                'name': project_name,\n\
    \                'id': project_info.get('id'),\n                'description':\
    \ project_data['description']\n            }\n        else:\n            L.error(f\"\
    Failed to create project: {create_response.status_code} - {create_response.text}\"\
    )\n            return None\n            \n    except Exception as e:\n       \
    \ L.error(f\"Exception creating project: {e}\")\n        return None\n\ndef create_test_issues(jira_url,\
    \ auth, timeout, project_key, issue_count=5):\n    \"\"\"\n    Create test issues\
    \ in the specified project.\n    \n    Args:\n        jira_url (str): Base JIRA\
    \ URL\n        auth (HTTPBasicAuth): Authentication object\n        timeout (int):\
    \ Request timeout\n        project_key (str): Project key to create issues in\n\
    \        issue_count (int): Number of issues to create\n        \n    Returns:\n\
    \        list: List of created issue information\n    \"\"\"\n    L.info(f\"Creating\
    \ {issue_count} test issues in project {project_key}\")\n    \n    created_issues\
    \ = []\n    \n    # Issue type templates\n    issue_templates = [\n        {\n\
    \            'summary': 'Setup development environment',\n            'description':\
    \ 'Configure the development environment with necessary tools and dependencies.',\n\
    \            'issuetype': 'Task'\n        },\n        {\n            'summary':\
    \ 'User authentication bug',\n            'description': 'Users are unable to\
    \ log in with valid credentials. Investigation needed.',\n            'issuetype':\
    \ 'Bug'\n        },\n        {\n            'summary': 'Add user profile page',\n\
    \            'description': 'Create a user profile page where users can view and\
    \ edit their information.',\n            'issuetype': 'Story'\n        },\n  \
    \      {\n            'summary': 'Database performance optimization',\n      \
    \      'description': 'Optimize database queries to improve application response\
    \ time.',\n            'issuetype': 'Task'\n        },\n        {\n          \
    \  'summary': 'Mobile app crashes on startup',\n            'description': 'The\
    \ mobile application crashes immediately after opening on Android devices.',\n\
    \            'issuetype': 'Bug'\n        },\n        {\n            'summary':\
    \ 'Implement search functionality',\n            'description': 'Add search capability\
    \ to allow users to find content quickly.',\n            'issuetype': 'Story'\n\
    \        },\n        {\n            'summary': 'Update API documentation',\n \
    \           'description': 'Review and update API documentation to reflect recent\
    \ changes.',\n            'issuetype': 'Task'\n        },\n        {\n       \
    \     'summary': 'Payment processing failure',\n            'description': 'Payment\
    \ transactions are failing intermittently. Requires immediate attention.',\n \
    \           'issuetype': 'Bug'\n        }\n    ]\n    \n    try:\n        # First,\
    \ get available issue types for the project\n        issuetypes_url = f\"{jira_url}/rest/api/2/project/{project_key}\"\
    \n        project_response = requests.get(\n            issuetypes_url,\n    \
    \        auth=auth,\n            timeout=timeout,\n            headers={'Accept':\
    \ 'application/json', 'Content-Type': 'application/json'}\n        )\n       \
    \ \n        available_issue_types = ['Task']  # Default fallback\n        if project_response.status_code\
    \ == 200:\n            project_info = project_response.json()\n            issue_types\
    \ = project_info.get('issueTypes', [])\n            available_issue_types = [it['name']\
    \ for it in issue_types]\n            L.info(f\"Available issue types: {', '.join(available_issue_types)}\"\
    )\n        \n        # Create issues\n        for i in range(issue_count):\n \
    \           # Select a random template\n            template = random.choice(issue_templates)\n\
    \            \n            # Ensure issue type exists in project, fallback to\
    \ first available\n            issue_type = template['issuetype']\n          \
    \  if issue_type not in available_issue_types:\n                issue_type = available_issue_types[0]\n\
    \            \n            # Add timestamp to make summaries unique\n        \
    \    timestamp = datetime.now().strftime('%H:%M:%S')\n            summary = f\"\
    {template['summary']} - {timestamp}\"\n            \n            issue_data =\
    \ {\n                \"fields\": {\n                    \"project\": {\n     \
    \                   \"key\": project_key\n                    },\n           \
    \         \"summary\": summary,\n                    \"description\": template['description'],\n\
    \                    \"issuetype\": {\n                        \"name\": issue_type\n\
    \                    }\n                }\n            }\n            \n     \
    \       create_issue_url = f\"{jira_url}/rest/api/2/issue\"\n            \n  \
    \          response = requests.post(\n                create_issue_url,\n    \
    \            auth=auth,\n                timeout=timeout,\n                headers={'Accept':\
    \ 'application/json', 'Content-Type': 'application/json'},\n                json=issue_data\n\
    \            )\n            \n            if response.status_code in [200, 201]:\n\
    \                issue_info = response.json()\n                issue_key = issue_info.get('key')\n\
    \                created_issues.append({\n                    'key': issue_key,\n\
    \                    'id': issue_info.get('id'),\n                    'summary':\
    \ summary,\n                    'issuetype': issue_type\n                })\n\
    \                L.info(f\"\u2705 Created issue: {issue_key} - {summary}\")\n\
    \                \n                # Small delay to avoid overwhelming the API\n\
    \                time.sleep(0.5)\n                \n            else:\n      \
    \          L.error(f\"Failed to create issue: {response.status_code} - {response.text}\"\
    )\n                # Continue creating other issues even if one fails\n      \
    \  \n        L.info(f\"Successfully created {len(created_issues)} out of {issue_count}\
    \ issues\")\n        return created_issues\n        \n    except Exception as\
    \ e:\n        L.error(f\"Exception creating issues: {e}\")\n        return created_issues\n\
    \ndef stage_test_data(min_projects=2, min_issues_per_project=3, min_total_issues=5):\n\
    \    \"\"\"\n    Stage test data in JIRA instance if insufficient data exists.\n\
    \    \n    Args:\n        min_projects (int): Minimum number of projects required\n\
    \        min_issues_per_project (int): Minimum issues per project required  \n\
    \        min_total_issues (int): Minimum total issues required\n        \n   \
    \ Returns:\n        bool: True if data staging was successful\n    \"\"\"\n  \
    \  L.info(\"Starting JIRA data staging process...\")\n    \n    try:\n       \
    \ # Connect to JIRA\n        jira_url, auth, timeout = connect_to_jira()\n   \
    \     \n        # Check existing data\n        existing_data = check_existing_data(jira_url,\
    \ auth, timeout)\n        if not existing_data:\n            L.error(\"Failed\
    \ to check existing data\")\n            return False\n        \n        # Determine\
    \ if data is sufficient\n        is_sufficient, missing_requirements = is_data_sufficient(\n\
    \            existing_data, min_projects, min_issues_per_project, min_total_issues\n\
    \        )\n        \n        if is_sufficient:\n            L.info(\"\u2705 Existing\
    \ data is sufficient for connector testing\")\n            L.info(\"No additional\
    \ data staging required\")\n            return True\n        \n        L.info(\"\
    \U0001F4DD Data staging required. Creating test data...\")\n        \n       \
    \ # Calculate what we need to create\n        projects_to_create = max(0, min_projects\
    \ - existing_data['total_projects'])\n        \n        # Create projects if needed\n\
    \        created_projects = []\n        if projects_to_create > 0:\n         \
    \   L.info(f\"Creating {projects_to_create} test projects...\")\n            \n\
    \            for i in range(projects_to_create):\n                timestamp =\
    \ datetime.now().strftime('%Y%m%d%H%M%S')\n                project = create_test_project(\n\
    \                    jira_url, auth, timeout,\n                    project_key=f\"\
    TST{timestamp[-4:]}{i+1:02d}\",\n                    project_name=f\"Test Project\
    \ {i+1} - {datetime.now().strftime('%Y-%m-%d')}\"\n                )\n       \
    \         \n                if project:\n                    created_projects.append(project)\n\
    \                    # Small delay between project creations\n               \
    \     time.sleep(1)\n                else:\n                    L.warning(f\"\
    Failed to create test project {i+1}\")\n        \n        # Create issues in projects\
    \ that need them\n        projects_needing_issues = []\n        \n        # Check\
    \ existing projects for issue count\n        for project_key, project_info in\
    \ existing_data['projects'].items():\n            if project_info['issue_count']\
    \ < min_issues_per_project:\n                projects_needing_issues.append(project_key)\n\
    \        \n        # Add newly created projects (they have 0 issues)\n       \
    \ for project in created_projects:\n            projects_needing_issues.append(project['key'])\n\
    \        \n        # Create issues in projects that need them\n        total_issues_created\
    \ = 0\n        for project_key in projects_needing_issues:\n            existing_issues\
    \ = existing_data['projects'].get(project_key, {}).get('issue_count', 0)\n   \
    \         issues_needed = max(min_issues_per_project - existing_issues, min_issues_per_project)\n\
    \            \n            L.info(f\"Creating {issues_needed} issues in project\
    \ {project_key}\")\n            created_issues = create_test_issues(jira_url,\
    \ auth, timeout, project_key, issues_needed)\n            total_issues_created\
    \ += len(created_issues)\n            \n            # Delay between projects\n\
    \            time.sleep(1)\n        \n        # Final verification\n        L.info(\"\
    Verifying staged data...\")\n        final_data = check_existing_data(jira_url,\
    \ auth, timeout)\n        \n        if final_data:\n            final_sufficient,\
    \ final_missing = is_data_sufficient(\n                final_data, min_projects,\
    \ min_issues_per_project, min_total_issues\n            )\n            \n    \
    \        if final_sufficient:\n                L.info(\"\u2705 Data staging completed\
    \ successfully!\")\n                L.info(f\"Final state: {final_data['total_projects']}\
    \ projects, {final_data['total_issues']} issues\")\n                return True\n\
    \            else:\n                L.warning(\"\u26A0\uFE0F  Data staging partially\
    \ successful but requirements still not fully met\")\n                L.info(f\"\
    Final state: {final_data['total_projects']} projects, {final_data['total_issues']}\
    \ issues\")\n                for req in final_missing:\n                    L.info(f\"\
    \  Still missing: {req}\")\n                # Return True anyway as we made progress\n\
    \                return True\n        else:\n            L.error(\"Failed to verify\
    \ final data state\")\n            return False\n            \n    except Exception\
    \ as e:\n        L.error(f\"Exception during data staging: {e}\")\n        return\
    \ False\n\ndef main():\n    L.info(\"JIRA Data Staging - Ensuring sufficient test\
    \ data exists\")\n    \n    if len(sys.argv) > 1 and sys.argv[1] == '--set-env':\n\
    \        L.info(\"Using manual credential input mode\")\n        \n        if\
    \ not os.environ.get('JIRA_URL'):\n            os.environ['JIRA_URL'] = input(\"\
    Enter JIRA URL (e.g., https://your-domain.atlassian.net): \")\n        if not\
    \ os.environ.get('JIRA_EMAIL'):\n            os.environ['JIRA_EMAIL'] = input(\"\
    Enter JIRA email address: \")\n        if not os.environ.get('JIRA_API_TOKEN'):\n\
    \            os.environ['JIRA_API_TOKEN'] = input(\"Enter JIRA API token: \")\n\
    \        if not os.environ.get('JIRA_API_REQUEST_TIMEOUT'):\n            timeout\
    \ = input(\"Enter request timeout in seconds (default 30): \")\n            os.environ['JIRA_API_REQUEST_TIMEOUT']\
    \ = timeout if timeout else '30'\n    else:\n        L.info(\"Using environment\
    \ variables for credentials\")\n    \n    # Parse command line arguments for requirements\n\
    \    min_projects = 2\n    min_issues_per_project = 3\n    min_total_issues =\
    \ 5\n    \n    if len(sys.argv) > 1:\n        for arg in sys.argv[1:]:\n     \
    \       if arg.startswith('--min-projects='):\n                min_projects =\
    \ int(arg.split('=')[1])\n            elif arg.startswith('--min-issues-per-project='):\n\
    \                min_issues_per_project = int(arg.split('=')[1])\n           \
    \ elif arg.startswith('--min-total-issues='):\n                min_total_issues\
    \ = int(arg.split('=')[1])\n    \n    L.info(f\"Data requirements: {min_projects}\
    \ projects, {min_issues_per_project} issues per project, {min_total_issues} total\
    \ issues\")\n    \n    success = stage_test_data(min_projects, min_issues_per_project,\
    \ min_total_issues)\n    \n    if success:\n        L.info(\"\u2705 JIRA data\
    \ staging completed successfully!\")\n        L.info(\"Target instance is valid\
    \ and has sufficient data for connector testing\")\n        return 0\n    else:\n\
    \        L.error(\"\u274C JIRA data staging failed\")\n        return 1\n\nif\
    \ __name__ == \"__main__\":\n    sys.exit(main())"
specs:
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files: {}
  description: "Implementation does not simulate, fake, or use dummy implementations\
    \ to cheat functionality \n"
  preconditions: 'A valid implementation and configuration

    '
  postconditions: "The implementation accomplishes the all specifications and unit\
    \ tests and code \ndoes not simulate, cheat, fake or use dummy implementations\
    \ for any aspect of it's functionality;\nIt does not simulate API calls, data,\
    \ or anything else of this nature;\n"
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files: {}
  description: "Connector Implementation handles API rate limiting and retries requests\
    \ when needed per it's \nimplementation in the code environment only\n"
  preconditions: 'A valid Connector implementation is provided

    '
  postconditions: "Connector gracefully handles rate-limiting responses; \n"
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files: {}
  description: "Evaluate that the Connector correctly inherits from ConnectorInterface\
    \ as defined in \nconnector.py. The spec will check that all required abstract\
    \ methods are implemented \nand that the connector can successfully perform a\
    \ connection check using valid configuration.\n"
  preconditions: 'Consider example connectors and connector interface as provided

    '
  postconditions: "Connector inherits and defines all necessary requirements of ConnectorInterface\
    \ per \nconnector.py per the provided interface\n"
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files: {}
  description: "This specification verifies that the Connector correctly implements\
    \ tools functionality by \ninheriting from ConnectorToolsInterface. It checks\
    \ that all required abstract methods are \nimplemented and return appropriately\
    \ and that the interface methods are defined and callable, \nmatching the behavior\
    \ of similar connectors provided for comparison\n"
  preconditions: 'Consider example connectors and connector interface as provided

    '
  postconditions: "Connector adheres to the ConnectorToolsInterface interface to define\
    \ tools as defined in \ntools.py and used in connector.py to define tools; consider\
    \ the example connector's \ntools.py for examples and considerations\n"
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files: {}
  description: "Connector implementation is entirely in the code environment, and\
    \ does not require external \nresources to be evaluated\n"
  preconditions: 'This spec has no strict preconditions

    '
  postconditions: "Entirety of the connector implementation, per the provided interfaces,\
    \ is entirely in the \ncode environment;\n"
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files: {}
  description: "Ensure that tool methods associated with connector operations are\
    \ implemented in the \ndedicated tool class rather than within the main connector\
    \ class, this holds for other classes\nas well\n"
  preconditions: "A connector exists which implements a main ConnectorInterface along\
    \ with a separate \nConnectorToolsInterface; tool methods should be clearly defined\
    \ in the tool class\n"
  postconditions: "The specification must confirm that all methods used to interact\
    \ with external APIs \n(e.g., get_asset_info, get_vulnerabilities, etc.) are part\
    \ of the tool class \nimplementation (i.e., subclass of ConnectorToolsInterface)\
    \ and not mixed into the main \nconnector class - this should intently hold for\
    \ other classes in the architecture\n"
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files: {}
  description: "Specification to ensure that the Connector delegates core functionality\
    \ to its dedicated \ntool class rather than having duplicate or recursive logic\
    \ within the connector. \nThis spec checks that tools contain the implementation\
    \ logic for interacting with the connector data\nsource, and that the connector\
    \ only serves as a configuration holder and dispatch mechanism\n"
  preconditions: "Connector must be instantiated with a valid configuration; Connector.get_tools()\
    \ should \nreturn a non-empty list of Tool objects where each tool has an execute_fn\
    \ defined; \nthe environment simulates API calls\n"
  postconditions: "For each core functionality tool provided by Connector the specification\
    \ must verify \nthat the implementation logic resides in the tool class and not\
    \ as \nredundant direct calls in the Connector. The spec should fail if the tool\u2019\
    s execute_fn \nsimply wraps a call back to the connector's methods or if there\
    \ is any sign of duplicate \nbusiness logic in both the connector and tool layers\n"
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files: {}
  description: "Specification to ensure that the Connector code maintains high stylistic\
    \ quality and does not contain dead, \nduplicate, or unnecessary code. This spec\
    \ checks that the implementation follows consistent coding \npatterns, is well-organized,\
    \ and only includes code that serves a functional purpose.\n"
  preconditions: "Connector implementation is complete and functional; all classes\
    \ and methods are defined \nand accessible; the code compiles without errors\n"
  postconditions: "The specification must verify that: (1) No unreachable or \"dead\"\
    \ code exists in the implementation; \n(2) No duplicate functionality is implemented\
    \ in multiple places; (3) All imports are actually used; \n(4) The code follows\
    \ a consistent style with proper naming conventions, indentation, and organization;\
    \ \n(5) There are no commented-out code blocks or TODOs that should have been\
    \ resolved; \n(6) No unnecessary abstractions or overly complex structures exist\
    \ where simpler solutions would suffice; \n(7) All \"placeholder\" or \"stub\"\
    \ code has been replaced with actual implementations\n"
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files: {}
  description: "Specification to ensure that the Connector implementation does not\
    \ contain any monkey-patches \nor runtime modifications to existing classes, methods,\
    \ or modules. This ensures code maintainability, \npredictability, and compatibility\
    \ with the framework.\n"
  preconditions: "Connector implementation is complete and functional; all modules\
    \ and classes are imported \nand initialized; the code compiles without errors\n"
  postconditions: "The specification must verify that: (1) No monkey-patching of framework\
    \ classes or methods exists \nin the implementation; (2) No runtime modifications\
    \ to class attributes or methods occur; \n(3) No dynamic attribute assignment\
    \ to external modules or classes is present; (4) No use of \nsetattr() or similar\
    \ techniques to modify behavior of imported modules; (5) All functionality \n\
    is implemented through proper inheritance, composition, or standard method overriding;\
    \ \n(6) The code does not modify __dict__, __class__, or other special attributes\
    \ of external objects; \n(7) No patching of built-in functions or standard library\
    \ modules occurs\n"
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files: {}
  description: "Specification to ensure that every tool, method, and input model in\
    \ the implementation \nincludes sufficiently descriptive docstrings. \n"
  preconditions: "Connector implementation is complete and contains all required tools,\
    \ models, and methods; \nthe code compiles without errors\n"
  postconditions: "The specification must verify that: (1) Every public class, method,\
    \ and function has a docstring that \nclearly explains its purpose and usage;\
    \ Most critically, the docstring MUST include how the \nfunction should be used\
    \ in terms of parameters and return values - this is especially critical \nfor\
    \ connector tools\n"
- provenance:
    source_file: domains/case_management/jira/jira.yaml
    domain: case_management
    manifest: jira
    referenced_files: {}
  description: "The JIRA Connector is able to authenticate with JIRA per it's implementation\
    \ in the code \nenvironment only\n"
  preconditions: 'This spec has no strict preconditions

    '
  postconditions: 'The JIRA connector is able to authenticate properly with a JIRA
    instance;

    The JIRA connector config is of type ConnectorConfig and not AlertProviderConnectorConfig;

    '
- provenance:
    source_file: domains/case_management/jira/jira.yaml
    domain: case_management
    manifest: jira
    referenced_files: {}
  description: 'JIRA Connector is able to list JIRA projects per user of get_query_target_options

    '
  preconditions: 'A valid authenticated session with JIRA

    '
  postconditions: 'Connector successfully enumerates projects to populate the target
    options of the JIRATarget;

    '
- provenance:
    source_file: domains/case_management/jira/jira.yaml
    domain: case_management
    manifest: jira
    referenced_files: {}
  description: 'JIRA Connector is able to list project information

    '
  preconditions: 'A valid authenticated session with JIRA

    '
  postconditions: 'Per the configuration as contained in JIRATarget as provided to
    JIRAConnectorTools, it is possible

    to get a list of projects along with their respective description and other relevant
    project details

    as may be relevant;

    Ensure that the respective get_jira_projects function in the JIRAConnectorTools
    is not hardcoding

    any return values;

    '
- provenance:
    source_file: domains/case_management/jira/jira.yaml
    domain: case_management
    manifest: jira
    referenced_files: {}
  description: 'JIRA Connector is able to list issues in a selected project

    '
  preconditions: 'A valid authenticated session with JIRA

    '
  postconditions: 'Connector successfully lists issues for the selected project provided
    as a param

    to the list issues tool

    '
- provenance:
    source_file: domains/case_management/jira/jira.yaml
    domain: case_management
    manifest: jira
    referenced_files: {}
  description: 'The connector should implement a JIRASecrets class to handle the decrypted
    API key.

    The get_secrets function should decrypt the StorableSecret and return a JIRASecrets
    instance.

    '
  preconditions: 'A valid JIRAConnectorConfig instance with an encrypted api_key field
    of type StorableSecret;

    A valid encryption key string that was used to encrypt the StorableSecret;

    The JIRASecrets class extends ConnectorSecretsInterface;

    The _get_secrets function is defined and passed to the Connector constructor;

    '
  postconditions: 'The JIRASecrets class has an api_key field of type SecretStr;

    The _get_secrets function successfully decrypts the StorableSecret from config.api_key
    using the provided encryption key;

    The _get_secrets function returns a JIRASecrets instance with the decrypted API
    key as a SecretStr;

    If a user_token is provided as a SecretStr, it takes precedence over the config.api_key;

    If neither user_token nor a valid decryptable api_key is available, _get_secrets
    returns None;

    The decrypted API key in JIRASecrets.api_key can be accessed via get_secret_value()
    method for use in authentication headers;

    The JIRASecrets instance is properly typed and can be passed to tools and connection
    check functions;

    '
tests:
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files: {}
  description: 'This checks to see that the connector is able to return a listing
    of tools

    '
  preconditions: 'A data connector implementation per the provided interfaces

    '
  postconditions: 'The data connector is able to provide a list of supported tools
    and interfaces

    '
  entry_point: test_tools_interface
  function_to_run: null
  code: "# 1-test_tools_interface.py\n\n\nasync def test_tools_interface(zerg_state=None):\n\
    \    \"\"\"Test whether connector returns a valid list of tools\"\"\"\n    print(\"\
    Testing connector tools interfaces\")\n\n    assert zerg_state, \"this test requires\
    \ valid zerg_state\"\n\n    jira_url = zerg_state.get(\"jira_url\").get(\"value\"\
    )\n    jira_api_token = zerg_state.get(\"jira_api_token\").get(\"value\")\n  \
    \  jira_email = zerg_state.get(\"jira_email\").get(\"value\")\n    confluence_url\
    \ = zerg_state.get(\"confluence_url\").get(\"value\")\n    confluence_api_token\
    \ = zerg_state.get(\"confluence_api_token\").get(\"value\")\n    confluence_email\
    \ = zerg_state.get(\"confluence_email\").get(\"value\")\n    github_api_url =\
    \ zerg_state.get(\"github_api_url\").get(\"value\")\n    github_access_token =\
    \ zerg_state.get(\"github_access_token\").get(\"value\")\n    sharepoint_url =\
    \ zerg_state.get(\"sharepoint_url\").get(\"value\")\n    sharepoint_client_id\
    \ = zerg_state.get(\"sharepoint_client_id\").get(\"value\")\n    sharepoint_client_secret\
    \ = zerg_state.get(\"sharepoint_client_secret\").get(\"value\")\n    sharepoint_tenant_id\
    \ = zerg_state.get(\"sharepoint_tenant_id\").get(\"value\")\n    salesforce_username\
    \ = zerg_state.get(\"salesforce_username\").get(\"value\")\n    salesforce_password\
    \ = zerg_state.get(\"salesforce_password\").get(\"value\")\n    salesforce_security_token\
    \ = zerg_state.get(\"salesforce_security_token\").get(\"value\")\n    salesforce_domain\
    \ = zerg_state.get(\"salesforce_domain\").get(\"value\")\n    zendesk_subdomain\
    \ = zerg_state.get(\"zendesk_subdomain\").get(\"value\")\n    zendesk_email =\
    \ zerg_state.get(\"zendesk_email\").get(\"value\")\n    zendesk_api_token = zerg_state.get(\"\
    zendesk_api_token\").get(\"value\")\n    asana_personal_access_token = zerg_state.get(\"\
    asana_personal_access_token\").get(\"value\")\n    sysaid_url = zerg_state.get(\"\
    sysaid_url\").get(\"value\")\n    sysaid_account_id = zerg_state.get(\"sysaid_account_id\"\
    ).get(\"value\")\n    sysaid_username = zerg_state.get(\"sysaid_username\").get(\"\
    value\")\n    sysaid_password = zerg_state.get(\"sysaid_password\").get(\"value\"\
    )\n    sysaid_api_key = zerg_state.get(\"sysaid_api_key\").get(\"value\")\n  \
    \  trello_api_key = zerg_state.get(\"trello_api_key\").get(\"value\")\n    trello_api_token\
    \ = zerg_state.get(\"trello_api_token\").get(\"value\")\n    trello_url = zerg_state.get(\"\
    trello_url\").get(\"value\")\n\n    from connectors.trello.connector.config import\
    \ TrelloConnectorConfig\n    from connectors.trello.connector.connector import\
    \ TrelloConnector, _get_secrets\n    from connectors.trello.connector.target import\
    \ TrelloTarget\n    from connectors.trello.connector.secrets import TrelloSecrets\n\
    \    from common.models.secret import StorableSecret\n\n    from connectors.config\
    \ import ConnectorConfig\n    from connectors.connector import Connector, ConnectorTargetInterface\n\
    \n    # Note this is common code\n    from common.models.tool import Tool\n  \
    \  from pydantic import SecretStr\n\n    # Define an encryption key for testing\n\
    \    encryption_key = \"test_encryption_key_32_chars_long\"\n\n    # Initialize\
    \ the connector config with StorableSecret for jira_api_token\n    # The jira_api_token\
    \ needs to be a StorableSecret which will encrypt the token\n    config = TrelloConnectorConfig(\n\
    \        url=jira_url,\n        api_key=StorableSecret.model_validate(\n     \
    \       {\"secret\": jira_api_token}, \n            context={\"encryption_key\"\
    : encryption_key}\n        ),\n        email=jira_email,\n        url=confluence_url,\n\
    \        api_token=StorableSecret.model_validate(\n            {\"secret\": confluence_api_token},\
    \ \n            context={\"encryption_key\": encryption_key}\n        ),\n   \
    \     email=confluence_email,\n        url=github_api_url,\n        access_token=StorableSecret.model_validate(\n\
    \            {\"secret\": github_access_token}, \n            context={\"encryption_key\"\
    : encryption_key}\n        ),\n        url=sharepoint_url,\n        client_id=sharepoint_client_id,\n\
    \        client_secret=StorableSecret.model_validate(\n            {\"secret\"\
    : sharepoint_client_secret}, \n            context={\"encryption_key\": encryption_key}\n\
    \        ),\n        tenant_id=sharepoint_tenant_id,\n        username=salesforce_username,\n\
    \        password=StorableSecret.model_validate(\n            {\"secret\": salesforce_password},\
    \ \n            context={\"encryption_key\": encryption_key}\n        ),\n   \
    \     security_token=StorableSecret.model_validate(\n            {\"secret\":\
    \ salesforce_security_token}, \n            context={\"encryption_key\": encryption_key}\n\
    \        ),\n        domain=salesforce_domain,\n        subdomain=zendesk_subdomain,\n\
    \        email=zendesk_email,\n        api_token=StorableSecret.model_validate(\n\
    \            {\"secret\": zendesk_api_token}, \n            context={\"encryption_key\"\
    : encryption_key}\n        ),\n        personal_access_token=StorableSecret.model_validate(\n\
    \            {\"secret\": asana_personal_access_token}, \n            context={\"\
    encryption_key\": encryption_key}\n        ),\n        url=sysaid_url,\n     \
    \   account_id=sysaid_account_id,\n        username=sysaid_username,\n       \
    \ password=StorableSecret.model_validate(\n            {\"secret\": sysaid_password},\
    \ \n            context={\"encryption_key\": encryption_key}\n        ),\n   \
    \     api_key=StorableSecret.model_validate(\n            {\"secret\": sysaid_api_key},\
    \ \n            context={\"encryption_key\": encryption_key}\n        ),\n   \
    \     api_key=StorableSecret.model_validate(\n            {\"secret\": trello_api_key},\
    \ \n            context={\"encryption_key\": encryption_key}\n        ),\n   \
    \     api_token=StorableSecret.model_validate(\n            {\"secret\": trello_api_token},\
    \ \n            context={\"encryption_key\": encryption_key}\n        ),\n   \
    \     url=trello_url,\n    )\n    assert isinstance(config, ConnectorConfig),\
    \ \"TrelloConnectorConfig should be of type ConnectorConfig\"\n\n    # The connector\
    \ is already instantiated as TrelloConnector, not a class to instantiate\n   \
    \ connector = TrelloConnector\n    \n    # TrelloConnector is an instance of Connector\n\
    \    assert isinstance(connector, Connector), \"TrelloConnector should be of type\
    \ Connector\"\n\n    target = TrelloTarget()\n    assert isinstance(target, ConnectorTargetInterface),\
    \ \"TrelloTarget should be of type ConnectorTargetInterface\"\n\n    # Get secrets\
    \ using the _get_secrets function directly\n    # This function is defined in\
    \ connector.py and passed to the Connector constructor\n    secrets = await _get_secrets(\n\
    \        config=config,\n        encryption_key=encryption_key,\n        user_token=None\
    \  # Not using user_token, using config.jira_api_token instead\n    )\n    assert\
    \ secrets is not None, \"Failed to get secrets\"\n    assert isinstance(secrets,\
    \ TrelloSecrets), \"Secrets should be of type TrelloSecrets\"\n    assert hasattr(secrets,\
    \ 'api_key'), \"Secrets should have api_key attribute\"\n    assert isinstance(secrets.api_key,\
    \ SecretStr), \"api_key should be a SecretStr\"\n    assert hasattr(secrets, 'api_token'),\
    \ \"Secrets should have api_token attribute\"\n    assert isinstance(secrets.api_token,\
    \ SecretStr), \"api_token should be a SecretStr\"\n    assert hasattr(secrets,\
    \ 'access_token'), \"Secrets should have access_token attribute\"\n    assert\
    \ isinstance(secrets.access_token, SecretStr), \"access_token should be a SecretStr\"\
    \n    assert hasattr(secrets, 'client_secret'), \"Secrets should have client_secret\
    \ attribute\"\n    assert isinstance(secrets.client_secret, SecretStr), \"client_secret\
    \ should be a SecretStr\"\n    assert hasattr(secrets, 'password'), \"Secrets\
    \ should have password attribute\"\n    assert isinstance(secrets.password, SecretStr),\
    \ \"password should be a SecretStr\"\n    assert hasattr(secrets, 'security_token'),\
    \ \"Secrets should have security_token attribute\"\n    assert isinstance(secrets.security_token,\
    \ SecretStr), \"security_token should be a SecretStr\"\n    assert hasattr(secrets,\
    \ 'api_token'), \"Secrets should have api_token attribute\"\n    assert isinstance(secrets.api_token,\
    \ SecretStr), \"api_token should be a SecretStr\"\n    assert hasattr(secrets,\
    \ 'personal_access_token'), \"Secrets should have personal_access_token attribute\"\
    \n    assert isinstance(secrets.personal_access_token, SecretStr), \"personal_access_token\
    \ should be a SecretStr\"\n    assert hasattr(secrets, 'password'), \"Secrets\
    \ should have password attribute\"\n    assert isinstance(secrets.password, SecretStr),\
    \ \"password should be a SecretStr\"\n    assert hasattr(secrets, 'api_key'),\
    \ \"Secrets should have api_key attribute\"\n    assert isinstance(secrets.api_key,\
    \ SecretStr), \"api_key should be a SecretStr\"\n    assert hasattr(secrets, 'api_key'),\
    \ \"Secrets should have api_key attribute\"\n    assert isinstance(secrets.api_key,\
    \ SecretStr), \"api_key should be a SecretStr\"\n    assert hasattr(secrets, 'api_token'),\
    \ \"Secrets should have api_token attribute\"\n    assert isinstance(secrets.api_token,\
    \ SecretStr), \"api_token should be a SecretStr\"\n\n    # Get tools using the\
    \ connector's get_tools function\n    # Note: get_tools expects config, target,\
    \ secrets, and cache\n    tools = connector.get_tools(\n        config=config,\n\
    \        target=target,\n        secrets=secrets,\n        cache=None  # Not using\
    \ cache in this test\n    )\n    assert isinstance(tools, list), \"Tools response\
    \ is not a list\"\n    \n    for tool in tools:\n        assert isinstance(tool,\
    \ Tool), f\"Item {tool} is not an instance of Tool\"\n\n    # Verify expected\
    \ tools are present\n    tool_names = [tool.name for tool in tools]\n    assert\
    \ \"get_trello_boards\" in tool_names, \"get_trello_boards tool not found\"\n\
    \    assert \"get_trello_lists\" in tool_names, \"get_trello_lists tool not found\"\
    \n    assert \"get_trello_cards\" in tool_names, \"get_trello_cards tool not found\"\
    \n\n    print(f\"Successfully retrieved {len(tools)} tools: {tool_names}\")\n\n\
    \    return True"
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files: {}
  description: 'This checks that the connector can successfully verify its connection

    '
  preconditions: 'A connector implementation adhering to ConnectorInterface is available
    as ''connector''

    '
  postconditions: 'The check_connection method returns True if the connector is correctly
    configured

    '
  entry_point: test_connector_check_connection
  function_to_run: null
  code: "# -test_connector_check_connection.py\n\n\nasync def test_connector_check_connection(zerg_state=None):\n\
    \    \"\"\"Test whether connector can successfully verify its connection\"\"\"\
    \n    print(\"Testing  connector connection\")\n\n    assert zerg_state, \"this\
    \ test requires valid zerg_state\"\n\n    jira_url = zerg_state.get(\"jira_url\"\
    ).get(\"value\")\n    jira_api_token = zerg_state.get(\"jira_api_token\").get(\"\
    value\")\n    jira_email = zerg_state.get(\"jira_email\").get(\"value\")\n   \
    \ confluence_url = zerg_state.get(\"confluence_url\").get(\"value\")\n    confluence_api_token\
    \ = zerg_state.get(\"confluence_api_token\").get(\"value\")\n    confluence_email\
    \ = zerg_state.get(\"confluence_email\").get(\"value\")\n    github_api_url =\
    \ zerg_state.get(\"github_api_url\").get(\"value\")\n    github_access_token =\
    \ zerg_state.get(\"github_access_token\").get(\"value\")\n    sharepoint_url =\
    \ zerg_state.get(\"sharepoint_url\").get(\"value\")\n    sharepoint_client_id\
    \ = zerg_state.get(\"sharepoint_client_id\").get(\"value\")\n    sharepoint_client_secret\
    \ = zerg_state.get(\"sharepoint_client_secret\").get(\"value\")\n    sharepoint_tenant_id\
    \ = zerg_state.get(\"sharepoint_tenant_id\").get(\"value\")\n    salesforce_username\
    \ = zerg_state.get(\"salesforce_username\").get(\"value\")\n    salesforce_password\
    \ = zerg_state.get(\"salesforce_password\").get(\"value\")\n    salesforce_security_token\
    \ = zerg_state.get(\"salesforce_security_token\").get(\"value\")\n    salesforce_domain\
    \ = zerg_state.get(\"salesforce_domain\").get(\"value\")\n    zendesk_subdomain\
    \ = zerg_state.get(\"zendesk_subdomain\").get(\"value\")\n    zendesk_email =\
    \ zerg_state.get(\"zendesk_email\").get(\"value\")\n    zendesk_api_token = zerg_state.get(\"\
    zendesk_api_token\").get(\"value\")\n    asana_personal_access_token = zerg_state.get(\"\
    asana_personal_access_token\").get(\"value\")\n    sysaid_url = zerg_state.get(\"\
    sysaid_url\").get(\"value\")\n    sysaid_account_id = zerg_state.get(\"sysaid_account_id\"\
    ).get(\"value\")\n    sysaid_username = zerg_state.get(\"sysaid_username\").get(\"\
    value\")\n    sysaid_password = zerg_state.get(\"sysaid_password\").get(\"value\"\
    )\n    sysaid_api_key = zerg_state.get(\"sysaid_api_key\").get(\"value\")\n  \
    \  trello_api_key = zerg_state.get(\"trello_api_key\").get(\"value\")\n    trello_api_token\
    \ = zerg_state.get(\"trello_api_token\").get(\"value\")\n    trello_url = zerg_state.get(\"\
    trello_url\").get(\"value\")\n\n    from connectors.trello.connector.config import\
    \ TrelloConnectorConfig\n    from connectors.trello.connector.connector import\
    \ TrelloConnector, check_connection, _get_secrets\n    from connectors.trello.connector.secrets\
    \ import TrelloSecrets\n    from common.models.secret import StorableSecret\n\
    \    \n    from connectors.config import ConnectorConfig\n    from connectors.connector\
    \ import Connector\n    from pydantic import SecretStr\n\n    # Define an encryption\
    \ key for testing\n    encryption_key = \"test_encryption_key_32_chars_long\"\n\
    \n    # Initialize the connector config with StorableSecret for jira_api_token\n\
    \    # The jira_api_token needs to be a StorableSecret which will encrypt the\
    \ token\n    config = TrelloConnectorConfig(\n        url=jira_url,\n        api_key=StorableSecret.model_validate(\n\
    \            {\"secret\": jira_api_token}, \n            context={\"encryption_key\"\
    : encryption_key}\n        ),\n        email=jira_email,\n        url=confluence_url,\n\
    \        api_token=StorableSecret.model_validate(\n            {\"secret\": confluence_api_token},\
    \ \n            context={\"encryption_key\": encryption_key}\n        ),\n   \
    \     email=confluence_email,\n        url=github_api_url,\n        access_token=StorableSecret.model_validate(\n\
    \            {\"secret\": github_access_token}, \n            context={\"encryption_key\"\
    : encryption_key}\n        ),\n        url=sharepoint_url,\n        client_id=sharepoint_client_id,\n\
    \        client_secret=StorableSecret.model_validate(\n            {\"secret\"\
    : sharepoint_client_secret}, \n            context={\"encryption_key\": encryption_key}\n\
    \        ),\n        tenant_id=sharepoint_tenant_id,\n        username=salesforce_username,\n\
    \        password=StorableSecret.model_validate(\n            {\"secret\": salesforce_password},\
    \ \n            context={\"encryption_key\": encryption_key}\n        ),\n   \
    \     security_token=StorableSecret.model_validate(\n            {\"secret\":\
    \ salesforce_security_token}, \n            context={\"encryption_key\": encryption_key}\n\
    \        ),\n        domain=salesforce_domain,\n        subdomain=zendesk_subdomain,\n\
    \        email=zendesk_email,\n        api_token=StorableSecret.model_validate(\n\
    \            {\"secret\": zendesk_api_token}, \n            context={\"encryption_key\"\
    : encryption_key}\n        ),\n        personal_access_token=StorableSecret.model_validate(\n\
    \            {\"secret\": asana_personal_access_token}, \n            context={\"\
    encryption_key\": encryption_key}\n        ),\n        url=sysaid_url,\n     \
    \   account_id=sysaid_account_id,\n        username=sysaid_username,\n       \
    \ password=StorableSecret.model_validate(\n            {\"secret\": sysaid_password},\
    \ \n            context={\"encryption_key\": encryption_key}\n        ),\n   \
    \     api_key=StorableSecret.model_validate(\n            {\"secret\": sysaid_api_key},\
    \ \n            context={\"encryption_key\": encryption_key}\n        ),\n   \
    \     api_key=StorableSecret.model_validate(\n            {\"secret\": trello_api_key},\
    \ \n            context={\"encryption_key\": encryption_key}\n        ),\n   \
    \     api_token=StorableSecret.model_validate(\n            {\"secret\": trello_api_token},\
    \ \n            context={\"encryption_key\": encryption_key}\n        ),\n   \
    \     url=trello_url,\n    )\n    assert isinstance(config, ConnectorConfig),\
    \ \"TrelloConnectorConfig should be of type ConnectorConfig\"\n\n    # The connector\
    \ is already instantiated as TrelloConnector\n    connector = TrelloConnector\n\
    \    assert isinstance(connector, Connector), \"TrelloConnector should be of type\
    \ Connector\"\n\n    # Get secrets for the connection check\n    secrets = await\
    \ _get_secrets(\n        config=config,\n        encryption_key=encryption_key,\n\
    \        user_token=None  # Not using user_token, using config. instead\n    )\n\
    \    assert secrets is not None, \"Failed to get secrets\"\n    assert isinstance(secrets,\
    \ TrelloSecrets), \"Secrets should be of type TrelloSecrets\"\n\n    # Check connection\
    \ using the check_connection function directly\n    # Note: check_connection is\
    \ a standalone function in connector.py that takes config and secrets\n    connection_valid\
    \ = await check_connection(\n        config=config,\n        secrets=secrets\n\
    \    )\n\n    if not isinstance(connection_valid, bool):\n        raise Exception(f\"\
    check_connection did not return a boolean, got {type(connection_valid)}\")\n \
    \   \n    if not connection_valid:\n        raise Exception(\"check_connection\
    \ returned False - connection failed\")\n\n    print(\"Connection check successful!\"\
    )\n\n    return True"
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files: {}
  description: 'Query target options successfully enumerates available resources

    '
  preconditions: 'Valid API credentials configured for the connector

    '
  postconditions: 'The get_query_target_options function retrieves a list of available
    resources;

    The returned options can be used to configure the connector''s target selection;

    The connector config is properly subclassed from ConnectorConfig;

    The enumerated resources are real (not simulated) and match the expected API response
    format;

    '
  entry_point: test_project_enumeration_options
  function_to_run: null
  code: "# 3-test_query_target_options.py\n\n\nasync def test_project_enumeration_options(zerg_state=None):\n\
    \    \"\"\"Test Trello project enumeration by way of query target options\"\"\"\
    \n    print(\"Attempting to authenticate using Trello connector\")\n\n    assert\
    \ zerg_state, \"this test requires valid zerg_state\"\n\n    jira_url = zerg_state.get(\"\
    jira_url\").get(\"value\")\n    jira_api_token = zerg_state.get(\"jira_api_token\"\
    ).get(\"value\")\n    jira_email = zerg_state.get(\"jira_email\").get(\"value\"\
    )\n    confluence_url = zerg_state.get(\"confluence_url\").get(\"value\")\n  \
    \  confluence_api_token = zerg_state.get(\"confluence_api_token\").get(\"value\"\
    )\n    confluence_email = zerg_state.get(\"confluence_email\").get(\"value\")\n\
    \    github_api_url = zerg_state.get(\"github_api_url\").get(\"value\")\n    github_access_token\
    \ = zerg_state.get(\"github_access_token\").get(\"value\")\n    sharepoint_url\
    \ = zerg_state.get(\"sharepoint_url\").get(\"value\")\n    sharepoint_client_id\
    \ = zerg_state.get(\"sharepoint_client_id\").get(\"value\")\n    sharepoint_client_secret\
    \ = zerg_state.get(\"sharepoint_client_secret\").get(\"value\")\n    sharepoint_tenant_id\
    \ = zerg_state.get(\"sharepoint_tenant_id\").get(\"value\")\n    salesforce_username\
    \ = zerg_state.get(\"salesforce_username\").get(\"value\")\n    salesforce_password\
    \ = zerg_state.get(\"salesforce_password\").get(\"value\")\n    salesforce_security_token\
    \ = zerg_state.get(\"salesforce_security_token\").get(\"value\")\n    salesforce_domain\
    \ = zerg_state.get(\"salesforce_domain\").get(\"value\")\n    zendesk_subdomain\
    \ = zerg_state.get(\"zendesk_subdomain\").get(\"value\")\n    zendesk_email =\
    \ zerg_state.get(\"zendesk_email\").get(\"value\")\n    zendesk_api_token = zerg_state.get(\"\
    zendesk_api_token\").get(\"value\")\n    asana_personal_access_token = zerg_state.get(\"\
    asana_personal_access_token\").get(\"value\")\n    sysaid_url = zerg_state.get(\"\
    sysaid_url\").get(\"value\")\n    sysaid_account_id = zerg_state.get(\"sysaid_account_id\"\
    ).get(\"value\")\n    sysaid_username = zerg_state.get(\"sysaid_username\").get(\"\
    value\")\n    sysaid_password = zerg_state.get(\"sysaid_password\").get(\"value\"\
    )\n    sysaid_api_key = zerg_state.get(\"sysaid_api_key\").get(\"value\")\n  \
    \  trello_api_key = zerg_state.get(\"trello_api_key\").get(\"value\")\n    trello_api_token\
    \ = zerg_state.get(\"trello_api_token\").get(\"value\")\n    trello_url = zerg_state.get(\"\
    trello_url\").get(\"value\")\n\n    from connectors.trello.connector.config import\
    \ TrelloConnectorConfig\n    from connectors.trello.connector.connector import\
    \ TrelloConnector, get_query_target_options, _get_secrets\n    from connectors.trello.connector.secrets\
    \ import TrelloSecrets\n    from common.models.secret import StorableSecret\n\n\
    \    from connectors.config import ConnectorConfig\n    from connectors.query_target_options\
    \ import ConnectorQueryTargetOptions\n    from connectors.connector import Connector\n\
    \    from pydantic import SecretStr\n\n    # Define an encryption key for testing\n\
    \    encryption_key = \"test_encryption_key_32_chars_long\"\n\n    # Initialize\
    \ the connector config with StorableSecret for jira_api_token\n    # The jira_api_token\
    \ needs to be a StorableSecret which will encrypt the token\n    config = TrelloConnectorConfig(\n\
    \        url=jira_url,\n        api_key=StorableSecret.model_validate(\n     \
    \       {\"secret\": jira_api_token}, \n            context={\"encryption_key\"\
    : encryption_key}\n        ),\n        email=jira_email,\n        url=confluence_url,\n\
    \        api_token=StorableSecret.model_validate(\n            {\"secret\": confluence_api_token},\
    \ \n            context={\"encryption_key\": encryption_key}\n        ),\n   \
    \     email=confluence_email,\n        url=github_api_url,\n        access_token=StorableSecret.model_validate(\n\
    \            {\"secret\": github_access_token}, \n            context={\"encryption_key\"\
    : encryption_key}\n        ),\n        url=sharepoint_url,\n        client_id=sharepoint_client_id,\n\
    \        client_secret=StorableSecret.model_validate(\n            {\"secret\"\
    : sharepoint_client_secret}, \n            context={\"encryption_key\": encryption_key}\n\
    \        ),\n        tenant_id=sharepoint_tenant_id,\n        username=salesforce_username,\n\
    \        password=StorableSecret.model_validate(\n            {\"secret\": salesforce_password},\
    \ \n            context={\"encryption_key\": encryption_key}\n        ),\n   \
    \     security_token=StorableSecret.model_validate(\n            {\"secret\":\
    \ salesforce_security_token}, \n            context={\"encryption_key\": encryption_key}\n\
    \        ),\n        domain=salesforce_domain,\n        subdomain=zendesk_subdomain,\n\
    \        email=zendesk_email,\n        api_token=StorableSecret.model_validate(\n\
    \            {\"secret\": zendesk_api_token}, \n            context={\"encryption_key\"\
    : encryption_key}\n        ),\n        personal_access_token=StorableSecret.model_validate(\n\
    \            {\"secret\": asana_personal_access_token}, \n            context={\"\
    encryption_key\": encryption_key}\n        ),\n        url=sysaid_url,\n     \
    \   account_id=sysaid_account_id,\n        username=sysaid_username,\n       \
    \ password=StorableSecret.model_validate(\n            {\"secret\": sysaid_password},\
    \ \n            context={\"encryption_key\": encryption_key}\n        ),\n   \
    \     api_key=StorableSecret.model_validate(\n            {\"secret\": sysaid_api_key},\
    \ \n            context={\"encryption_key\": encryption_key}\n        ),\n   \
    \     api_key=StorableSecret.model_validate(\n            {\"secret\": trello_api_key},\
    \ \n            context={\"encryption_key\": encryption_key}\n        ),\n   \
    \     api_token=StorableSecret.model_validate(\n            {\"secret\": trello_api_token},\
    \ \n            context={\"encryption_key\": encryption_key}\n        ),\n   \
    \     url=trello_url,\n    )\n    assert isinstance(config, ConnectorConfig),\
    \ \"TrelloConnectorConfig should be of type ConnectorConfig\"\n\n    # The connector\
    \ is already instantiated as TrelloConnector\n    connector = TrelloConnector\n\
    \    assert isinstance(connector, Connector), \"TrelloConnector should be of type\
    \ Connector\"\n\n    # Get secrets for the query target options call\n    secrets\
    \ = await _get_secrets(\n        config=config,\n        encryption_key=encryption_key,\n\
    \        user_token=None  # Not using user_token, using config.api_key instead\n\
    \    )\n    assert secrets is not None, \"Failed to get secrets\"\n    assert\
    \ isinstance(secrets, TrelloSecrets), \"Secrets should be of type TrelloSecrets\"\
    \n\n    # Get query target options using the standalone function\n    # Note:\
    \ get_query_target_options is a function that takes config and secrets\n    trello_query_target_options\
    \ = await get_query_target_options(\n        config=config,\n        secrets=secrets\n\
    \    )\n    assert isinstance(trello_query_target_options, ConnectorQueryTargetOptions),\
    \ \"query target options should be of type ConnectorQueryTargetOptions\"\n\n \
    \   assert trello_query_target_options, \"Failed to retrieve query target options\"\
    \n\n    # Validate the structure of query target options\n    assert trello_query_target_options.definitions,\
    \ \"Query target options should have definitions\"\n    assert trello_query_target_options.selectors,\
    \ \"Query target options should have selectors\"\n    \n    # Check that we have\
    \ the expected definition for project_keys\n    definition_names = [d.name for\
    \ d in trello_query_target_options.definitions]\n    # board_ids selector for\
    \ target board\n    assert \"board_ids\" in definition_names, \"board_ids should\
    \ be in definitions\"\n\n    # Find the board_ids definition and validate it\n\
    \    board_ids_def = next(d for d in trello_query_target_options.definitions if\
    \ d.name == \"board_ids\")\n    assert board_ids_def.multiselect is True, \"board_ids\
    \ should be multiselect\"\n    \n    # Check that we have selectors with board\
    \ values\n    assert len(trello_query_target_options.selectors) > 0, \"Should\
    \ have at least one selector\"\n    board_selector = next((s for s in trello_query_target_options.selectors\
    \ if s.type == \"board_ids\"), None)\n    assert board_selector is not None, \"\
    Should have a board_ids selector\"\n    assert len(board_selector.values) > 0,\
    \ \"Should have at least one board value\"\n    \n    # These should be real board_idss\
    \ from Trello\n    print(f\"Found {len(board_selector.values)} Trello boards:\
    \ {board_selector.values}\")\n    \n    # Verify these are actual board_ids\n\
    \    for board_key in board_selector.values:\n        assert isinstance(board_key,\
    \ str), f\"board_ids {board_key} should be a string\"\n        assert len(board_key)\
    \ > 0, f\"board_ids should not be empty\"\n\n    print(f\"trello query target\
    \ option definitions: {trello_query_target_options.definitions}\")\n    print(f\"\
    trello query target option selectors: {trello_query_target_options.selectors}\"\
    )\n\n    return True"
- provenance:
    source_file: domains/case_management/jira/jira.yaml
    domain: case_management
    manifest: jira
    referenced_files:
      '!python/file:4-test_list_projects.py':
        directive: '!python/file'
        original_path: 4-test_list_projects.py
        function_name: null
        resolved_path: domains/case_management/jira/4-test_list_projects.py
  description: 'List JIRA projects for selected JIRA projects in target

    '
  preconditions: 'An existing JIRA API key and credentials

    '
  postconditions: "Possible to retrieve the list of JIRA projects by way of connector\
    \ tools;\nThis list includes details of the projects to be listed in results;\
    \ \nThese must be real projects, and not simulated;\n"
  entry_point: test_list_projects
  function_to_run: null
  code: "# 4-test_list_projects.py\n\nasync def test_list_projects(zerg_state=None):\n\
    \    \"\"\"Test JIRA project listing through connector tools\"\"\"\n    print(\"\
    Testing JIRA project listing via connector tools\")\n\n    assert zerg_state,\
    \ \"this test requires valid zerg_state\"\n\n    jira_url = zerg_state.get(\"\
    jira_url\").get(\"value\")\n    jira_api_token = zerg_state.get(\"jira_api_token\"\
    ).get(\"value\")\n    jira_email = zerg_state.get(\"jira_email\").get(\"value\"\
    )\n\n    from connectors.jira.connector.config import JIRAConnectorConfig\n  \
    \  from connectors.jira.connector.connector import JIRAConnector, get_query_target_options,\
    \ _get_secrets\n    from connectors.jira.connector.tools import JIRAConnectorTools,\
    \ GetJIRAProjectsInput\n    from connectors.jira.connector.target import JIRATarget\n\
    \    from connectors.jira.connector.secrets import JIRASecrets\n    from common.models.secret\
    \ import StorableSecret\n\n    from connectors.config import ConnectorConfig\n\
    \    from connectors.connector import Connector, ConnectorTargetInterface\n  \
    \  from connectors.query_target_options import ConnectorQueryTargetOptions\n \
    \   from pydantic import SecretStr\n    \n    # Define an encryption key for testing\n\
    \    encryption_key = \"test_encryption_key_32_chars_long\"\n\n    # Set up the\
    \ config with StorableSecret for api_key\n    config = JIRAConnectorConfig(\n\
    \        url=jira_url,\n        api_key=StorableSecret.model_validate(\n     \
    \       {\"secret\": jira_api_token}, \n            context={\"encryption_key\"\
    : encryption_key}\n        ),\n        email=jira_email\n    )\n    assert isinstance(config,\
    \ ConnectorConfig), \"JIRAConnectorConfig should be of type ConnectorConfig\"\n\
    \n    # The connector is already instantiated\n    connector = JIRAConnector\n\
    \    assert isinstance(connector, Connector), \"JIRAConnector should be of type\
    \ Connector\"\n\n    # Get secrets\n    secrets = await _get_secrets(\n      \
    \  config=config,\n        encryption_key=encryption_key,\n        user_token=None\n\
    \    )\n    assert secrets is not None, \"Failed to get secrets\"\n    assert\
    \ isinstance(secrets, JIRASecrets), \"Secrets should be of type JIRASecrets\"\n\
    \n    # Get query target options to find available projects\n    jira_query_target_options\
    \ = await get_query_target_options(\n        config=config,\n        secrets=secrets\n\
    \    )\n    assert isinstance(jira_query_target_options, ConnectorQueryTargetOptions),\
    \ \"query target options should be of type ConnectorQueryTargetOptions\"\n\n \
    \   # Select projects to target\n    project_selector = None\n    for selector\
    \ in jira_query_target_options.selectors:\n        if selector.type == 'project_keys':\
    \  \n            project_selector = selector\n            break\n\n    assert\
    \ project_selector, \"failed to retrieve project selector from query target options\"\
    \n\n    # Grab the first two projects \n    num_projects = 2\n    assert isinstance(project_selector.values,\
    \ list), \"project_selector values must be a list\"\n    assert len(project_selector.values)\
    \ >= num_projects, f\"Need at least {num_projects} projects available\"\n    project_keys\
    \ = project_selector.values[:num_projects]\n    print(f\"Selecting project keys:\
    \ {project_keys}\")\n\n    assert project_keys, f\"failed to retrieve {num_projects}\
    \ project keys from project selector\"\n\n    # Set up the target with project\
    \ keys\n    target = JIRATarget(project_keys=project_keys)\n    assert isinstance(target,\
    \ ConnectorTargetInterface), \"JIRATarget should be of type ConnectorTargetInterface\"\
    \n\n    # Get tools using the connector's get_tools function\n    tools = connector.get_tools(\n\
    \        config=config,\n        target=target,\n        secrets=secrets,\n  \
    \      cache=None\n    )\n    assert isinstance(tools, list), \"Tools response\
    \ is not a list\"\n    assert len(tools) > 0, \"Should have at least one tool\"\
    \n\n    # Find the get_jira_projects tool\n    jira_get_projects_tool = None\n\
    \    for tool in tools:\n        if tool.name == \"get_jira_projects\":\n    \
    \        jira_get_projects_tool = tool\n            break\n    \n    assert jira_get_projects_tool\
    \ is not None, \"get_jira_projects tool not found\"\n\n    # Execute the tool\
    \ with proper input\n    # The GetJIRAProjectsInput model has no required fields\n\
    \    projects_input = GetJIRAProjectsInput()\n    jira_projects_result = await\
    \ jira_get_projects_tool.execute_fn(projects_input)\n    \n    # The result should\
    \ be a list of projects directly (not wrapped in ToolResult here since execute_fn\
    \ returns the raw result)\n    jira_projects = jira_projects_result\n\n    print(\"\
    Type of returned jira_projects:\", type(jira_projects))\n    print(f\"len projects:\
    \ {len(jira_projects)} projects: {str(jira_projects)[:200]}\")\n\n    # Verify\
    \ that jira_projects is a list\n    assert isinstance(jira_projects, list), \"\
    jira_projects should be a list\"\n    assert len(jira_projects) > 0, \"jira_projects\
    \ should not be empty\"\n    assert len(jira_projects) == num_projects, f\"jira_projects\
    \ should have {num_projects} entries (filtered by target)\"\n    \n    # Verify\
    \ structure of each project object\n    for project in jira_projects:\n      \
    \  assert isinstance(project, dict), \"Each project should be a dictionary\"\n\
    \        assert \"key\" in project, \"Each project should have a 'key' field\"\
    \n        assert project[\"key\"] in project_keys, f\"Project key {project['key']}\
    \ is not in the requested project_keys\"\n        \n        # Verify essential\
    \ JIRA project fields\n        # These are common fields in JIRA projects based\
    \ on JIRA API specification\n        assert \"id\" in project, \"Each project\
    \ should have an 'id' field\"\n        assert \"name\" in project, \"Each project\
    \ should have a 'name' field\"\n        \n        # Check for additional descriptive\
    \ fields (optional in some JIRA instances)\n        descriptive_fields = [\"description\"\
    , \"projectTypeKey\", \"url\", \"self\", \"lead\", \"components\", \"issueTypes\"\
    ]\n        present_fields = [field for field in descriptive_fields if field in\
    \ project]\n        \n        if present_fields:\n            print(f\"Project\
    \ {project['key']} contains these descriptive fields: {', '.join(present_fields)}\"\
    )\n        \n        # Ensure this is real data, not hardcoded\n        assert\
    \ project[\"id\"] != \"hardcoded\", \"Project data should be from real JIRA API,\
    \ not hardcoded\"\n        assert project[\"name\"] != \"Test Project\", \"Project\
    \ data should be from real JIRA API, not simulated\"\n        \n        # Log\
    \ the full structure of the first project\n        if project == jira_projects[0]:\n\
    \            import json\n            print(f\"Example project structure: {json.dumps(project,\
    \ indent=2, default=str)[:500]}...\")\n\n    print(f\"Successfully retrieved and\
    \ validated {len(jira_projects)} JIRA projects\")\n    print(\"Verified that projects\
    \ are real (not simulated) and properly filtered by target\")\n\n    return True"
- provenance:
    source_file: domains/case_management/jira/jira.yaml
    domain: case_management
    manifest: jira
    referenced_files:
      '!python/file:5-test_issue_retrieval.py':
        directive: '!python/file'
        original_path: 5-test_issue_retrieval.py
        function_name: null
        resolved_path: domains/case_management/jira/5-test_issue_retrieval.py
  description: 'Retrieve issues for selected JIRA project passed as param

    '
  preconditions: 'An existing JIRA API key and credentials

    '
  postconditions: "Possible to retrieve a set of issues for the selected JIRA project\
    \ as passed as a param to the connector tools;\nThis list only includes issues\
    \ of the target project to be listed in results; \nThese must be real issues,\
    \ and not simulated;\n"
  entry_point: test_issue_retrieval
  function_to_run: null
  code: "# 5-test_issue_retrieval.py\n\nasync def test_issue_retrieval(zerg_state=None):\n\
    \    \"\"\"Test JIRA issue retrieval for a specific project\"\"\"\n    print(\"\
    Testing JIRA issue retrieval via connector tools\")\n\n    assert zerg_state,\
    \ \"this test requires valid zerg_state\"\n\n    jira_url = zerg_state.get(\"\
    jira_url\").get(\"value\")\n    jira_api_token = zerg_state.get(\"jira_api_token\"\
    ).get(\"value\")\n    jira_email = zerg_state.get(\"jira_email\").get(\"value\"\
    )\n\n    from connectors.jira.connector.config import JIRAConnectorConfig\n  \
    \  from connectors.jira.connector.connector import JIRAConnector, get_query_target_options,\
    \ _get_secrets\n    from connectors.jira.connector.tools import JIRAConnectorTools,\
    \ GetJIRAIssuesInput\n    from connectors.jira.connector.target import JIRATarget\n\
    \    from connectors.jira.connector.secrets import JIRASecrets\n    from common.models.secret\
    \ import StorableSecret\n    from common.models.tool import ToolResult\n\n   \
    \ from connectors.config import ConnectorConfig\n    from connectors.connector\
    \ import Connector, ConnectorTargetInterface\n    from connectors.query_target_options\
    \ import ConnectorQueryTargetOptions\n    from pydantic import SecretStr\n\n \
    \   # Define an encryption key for testing\n    encryption_key = \"test_encryption_key_32_chars_long\"\
    \n\n    # Set up the config with StorableSecret for api_key\n    config = JIRAConnectorConfig(\n\
    \        url=jira_url,\n        api_key=StorableSecret.model_validate(\n     \
    \       {\"secret\": jira_api_token}, \n            context={\"encryption_key\"\
    : encryption_key}\n        ),\n        email=jira_email\n    )\n    assert isinstance(config,\
    \ ConnectorConfig), \"JIRAConnectorConfig should be of type ConnectorConfig\"\n\
    \n    # The connector is already instantiated\n    connector = JIRAConnector\n\
    \    assert isinstance(connector, Connector), \"JIRAConnector should be of type\
    \ Connector\"\n\n    # Get secrets\n    secrets = await _get_secrets(\n      \
    \  config=config,\n        encryption_key=encryption_key,\n        user_token=None\n\
    \    )\n    assert secrets is not None, \"Failed to get secrets\"\n    assert\
    \ isinstance(secrets, JIRASecrets), \"Secrets should be of type JIRASecrets\"\n\
    \n    # Get query target options to find available projects\n    jira_query_target_options\
    \ = await get_query_target_options(\n        config=config,\n        secrets=secrets\n\
    \    )\n    assert isinstance(jira_query_target_options, ConnectorQueryTargetOptions),\
    \ \"query target options should be of type ConnectorQueryTargetOptions\"\n\n \
    \   # Select a project to target\n    project_selector = None\n    for selector\
    \ in jira_query_target_options.selectors:\n        if selector.type == 'project_keys':\
    \  \n            project_selector = selector\n            break\n\n    assert\
    \ project_selector, \"failed to retrieve project selector from query target options\"\
    \n\n    assert isinstance(project_selector.values, list), \"project_selector values\
    \ must be a list\"\n    assert len(project_selector.values) > 0, \"Need at least\
    \ one project available\"\n    project_key = project_selector.values[0]\n    print(f\"\
    Selecting project key: {project_key}\")\n\n    assert project_key, \"failed to\
    \ retrieve project key from project selector\"\n\n    # Set up the target with\
    \ project key\n    # Note: Even though we're querying a specific project, the\
    \ target is used for filtering\n    target = JIRATarget(project_keys=[project_key])\n\
    \    assert isinstance(target, ConnectorTargetInterface), \"JIRATarget should\
    \ be of type ConnectorTargetInterface\"\n\n    # Get tools using the connector's\
    \ get_tools function\n    tools = connector.get_tools(\n        config=config,\n\
    \        target=target,\n        secrets=secrets,\n        cache=None\n    )\n\
    \    assert isinstance(tools, list), \"Tools response is not a list\"\n    assert\
    \ len(tools) > 0, \"Should have at least one tool\"\n\n    # Find the get_jira_issues\
    \ tool\n    get_jira_issues_tool = None\n    for tool in tools:\n        if tool.name\
    \ == \"get_jira_issues\":\n            get_jira_issues_tool = tool\n         \
    \   break\n    \n    assert get_jira_issues_tool is not None, \"get_jira_issues\
    \ tool not found\"\n\n    # Execute the tool with proper input\n    # The GetJIRAIssuesInput\
    \ requires a project_key parameter\n    issues_input = GetJIRAIssuesInput(project_key=project_key)\n\
    \    jira_issues_result = await get_jira_issues_tool.execute_fn(issues_input)\n\
    \    \n    # The _get_jira_issues_async method returns a ToolResult\n    assert\
    \ isinstance(jira_issues_result, ToolResult), \"Result should be a ToolResult\"\
    \n    jira_issues = jira_issues_result.result\n\n    print(\"Type of returned\
    \ jira_issues:\", type(jira_issues))\n    print(f\"Number of issues: {len(jira_issues)}\"\
    )\n    if jira_issues:\n        print(f\"Sample issues: {str(jira_issues[:2])[:500]}...\"\
    )\n\n    # Verify that jira_issues is a list\n    assert isinstance(jira_issues,\
    \ list), \"jira_issues should be a list\"\n    \n    # It's possible a project\
    \ has no issues, so we check if there are issues to validate\n    if len(jira_issues)\
    \ > 0:\n        print(f\"Found {len(jira_issues)} issues in project {project_key}\"\
    )\n        \n        # Limit the number of issues to check if there are many\n\
    \        issues_to_check = jira_issues[:5] if len(jira_issues) > 5 else jira_issues\n\
    \        \n        # Verify structure of each issue object\n        for issue\
    \ in issues_to_check:\n            assert isinstance(issue, dict), \"Each issue\
    \ should be a dictionary\"\n            \n            # Verify essential JIRA\
    \ issue fields\n            assert \"key\" in issue, \"Each issue should have\
    \ a 'key' field\"\n            assert \"id\" in issue, \"Each issue should have\
    \ an 'id' field\"\n            \n            # Check if issue belongs to the requested\
    \ project\n            # JIRA issue keys follow the format PROJECT-NUMBER (e.g.,\
    \ PROJ-123)\n            issue_project_key = issue.get(\"key\", \"\").split(\"\
    -\")[0] if \"-\" in issue.get(\"key\", \"\") else None\n            assert issue_project_key\
    \ == project_key, f\"Issue {issue['key']} does not belong to project {project_key}\"\
    \n            \n            # Verify common JIRA issue fields\n            assert\
    \ \"self\" in issue, \"Each issue should have a 'self' field (URL)\"\n       \
    \     \n            # Check for fields object which contains most issue data\n\
    \            assert \"fields\" in issue, \"Each issue should have a 'fields' object\"\
    \n            fields = issue[\"fields\"]\n            \n            # Check for\
    \ essential fields\n            essential_fields = [\"summary\", \"issuetype\"\
    , \"status\", \"created\"]\n            for field in essential_fields:\n     \
    \           assert field in fields, f\"Issue fields should contain '{field}'\"\
    \n            \n            # Ensure this is real data, not simulated\n      \
    \      assert not issue[\"key\"].startswith(\"MOCK-\"), \"Issues should be from\
    \ real JIRA API, not mocked\"\n            assert fields.get(\"summary\") != \"\
    Test Issue\", \"Issues should be real, not simulated\"\n            \n       \
    \     # Additional optional fields to check (if present)\n            optional_fields\
    \ = [\"description\", \"assignee\", \"reporter\", \"priority\", \"labels\", \"\
    components\", \"fixVersions\"]\n            present_optional = [field for field\
    \ in optional_fields if field in fields]\n            \n            if present_optional:\n\
    \                print(f\"Issue {issue['key']} contains these optional fields:\
    \ {', '.join(present_optional)}\")\n            \n            # Log the structure\
    \ of the first issue for debugging\n            if issue == issues_to_check[0]:\n\
    \                import json\n                print(f\"Example issue structure\
    \ (truncated): {json.dumps(issue, indent=2, default=str)[:800]}...\")\n\n    \
    \    print(f\"Successfully retrieved and validated {len(jira_issues)} JIRA issues\
    \ from project {project_key}\")\n    else:\n        print(f\"Project {project_key}\
    \ has no issues (this is valid)\")\n        # Even with no issues, the response\
    \ should still be a valid empty list\n        assert jira_issues == [], \"Empty\
    \ project should return empty list, not None\"\n\n    print(\"Verified that issues\
    \ are real (not simulated) and belong to the correct project\")\n\n    return\
    \ True"
references:
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/connectors_code/connectors/tenable/connector/connector.py:
        directive: null
        original_path: andesite/connectors_code/connectors/tenable/connector/connector.py
        function_name: null
        resolved_path: andesite/connectors_code/connectors/tenable/connector/connector.py
  url: null
  file_path: workspace/tenable_connector_example/connector.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/workspace/tenable_connector_example/connector.py
  workspace_path: workspace/tenable_connector_example/connector.py
  environment_path: null
  description: example connector.py of a tenable connector for purpose of comparison
  format: python
  required: true
  read_only: true
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/connectors_code/connectors/tenable/connector/config.py:
        directive: null
        original_path: andesite/connectors_code/connectors/tenable/connector/config.py
        function_name: null
        resolved_path: andesite/connectors_code/connectors/tenable/connector/config.py
  url: null
  file_path: workspace/tenable_connector_example/config.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/workspace/tenable_connector_example/config.py
  workspace_path: workspace/tenable_connector_example/config.py
  environment_path: null
  description: example config.py of a tenable connector for purpose of comparison
  format: python
  required: true
  read_only: true
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/connectors_code/connectors/tenable/connector/target.py:
        directive: null
        original_path: andesite/connectors_code/connectors/tenable/connector/target.py
        function_name: null
        resolved_path: andesite/connectors_code/connectors/tenable/connector/target.py
  url: null
  file_path: workspace/tenable_connector_example/target.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/workspace/tenable_connector_example/target.py
  workspace_path: workspace/tenable_connector_example/target.py
  environment_path: null
  description: example target.py of a tenable connector for purpose of comparison
  format: python
  required: true
  read_only: true
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/connectors_code/connectors/tenable/connector/tools.py:
        directive: null
        original_path: andesite/connectors_code/connectors/tenable/connector/tools.py
        function_name: null
        resolved_path: andesite/connectors_code/connectors/tenable/connector/tools.py
  url: null
  file_path: workspace/tenable_connector_example/tools.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/workspace/tenable_connector_example/tools.py
  workspace_path: workspace/tenable_connector_example/tools.py
  environment_path: null
  description: example tools.py of a tenable connector for purpose of comparison
  format: python
  required: true
  read_only: true
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/connectors_code/connectors/splunk/connector/connector.py:
        directive: null
        original_path: andesite/connectors_code/connectors/splunk/connector/connector.py
        function_name: null
        resolved_path: andesite/connectors_code/connectors/splunk/connector/connector.py
  url: null
  file_path: workspace/splunk_connector_example/connector.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/workspace/splunk_connector_example/connector.py
  workspace_path: workspace/splunk_connector_example/connector.py
  environment_path: null
  description: example connector.py of a splunk connector for purpose of comparison
  format: python
  required: true
  read_only: true
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/connectors_code/connectors/splunk/connector/alerts.py:
        directive: null
        original_path: andesite/connectors_code/connectors/splunk/connector/alerts.py
        function_name: null
        resolved_path: andesite/connectors_code/connectors/splunk/connector/alerts.py
  url: null
  file_path: workspace/splunk_connector_example/alerts.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/workspace/splunk_connector_example/alerts.py
  workspace_path: workspace/splunk_connector_example/alerts.py
  environment_path: null
  description: example alerts.py of a splunk connector for purpose of comparison
  format: python
  required: true
  read_only: true
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/connectors_code/connectors/splunk/connector/config.py:
        directive: null
        original_path: andesite/connectors_code/connectors/splunk/connector/config.py
        function_name: null
        resolved_path: andesite/connectors_code/connectors/splunk/connector/config.py
  url: null
  file_path: workspace/splunk_connector_example/config.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/workspace/splunk_connector_example/config.py
  workspace_path: workspace/splunk_connector_example/config.py
  environment_path: null
  description: example config.py of a splunk connector for purpose of comparison
  format: python
  required: true
  read_only: true
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/connectors_code/connectors/splunk/connector/target.py:
        directive: null
        original_path: andesite/connectors_code/connectors/splunk/connector/target.py
        function_name: null
        resolved_path: andesite/connectors_code/connectors/splunk/connector/target.py
  url: null
  file_path: workspace/splunk_connector_example/target.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/workspace/splunk_connector_example/target.py
  workspace_path: workspace/splunk_connector_example/target.py
  environment_path: null
  description: example target.py of a splunk connector for purpose of comparison
  format: python
  required: true
  read_only: true
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/connectors_code/connectors/splunk/connector/tools.py:
        directive: null
        original_path: andesite/connectors_code/connectors/splunk/connector/tools.py
        function_name: null
        resolved_path: andesite/connectors_code/connectors/splunk/connector/tools.py
  url: null
  file_path: workspace/splunk_connector_example/tools.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/workspace/splunk_connector_example/tools.py
  workspace_path: workspace/splunk_connector_example/tools.py
  environment_path: null
  description: example tools.py of a splunk connector for purpose of comparison
  format: python
  required: true
  read_only: true
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/connectors_code/connectors/cache.py:
        directive: null
        original_path: andesite/connectors_code/connectors/cache.py
        function_name: null
        resolved_path: andesite/connectors_code/connectors/cache.py
  url: null
  file_path: connectors/cache.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/environment/connectors/cache.py
  workspace_path: null
  environment_path: connectors/cache.py
  description: cache.py
  format: python
  required: true
  read_only: true
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/connectors_code/connectors/config.py:
        directive: null
        original_path: andesite/connectors_code/connectors/config.py
        function_name: null
        resolved_path: andesite/connectors_code/connectors/config.py
  url: null
  file_path: connectors/config.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/environment/connectors/config.py
  workspace_path: null
  environment_path: connectors/config.py
  description: config.py defines the connector config interfaces that the connector
    must use
  format: python
  required: true
  read_only: true
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/connectors_code/connectors/connector.py:
        directive: null
        original_path: andesite/connectors_code/connectors/connector.py
        function_name: null
        resolved_path: andesite/connectors_code/connectors/connector.py
  url: null
  file_path: connectors/connector.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/environment/connectors/connector.py
  workspace_path: null
  environment_path: connectors/connector.py
  description: connector.py defines the connector interface that the connector must
    adhere to and inherit
  format: python
  required: true
  read_only: true
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/connectors_code/connectors/initialize_connector_scopes.py:
        directive: null
        original_path: andesite/connectors_code/connectors/initialize_connector_scopes.py
        function_name: null
        resolved_path: andesite/connectors_code/connectors/initialize_connector_scopes.py
  url: null
  file_path: connectors/initialize_connector_scopes.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/environment/connectors/initialize_connector_scopes.py
  workspace_path: null
  environment_path: connectors/initialize_connector_scopes.py
  description: initialize_connector_scopes.py defines connector scope initialization
  format: python
  required: true
  read_only: true
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/connectors_code/connectors/main.py:
        directive: null
        original_path: andesite/connectors_code/connectors/main.py
        function_name: null
        resolved_path: andesite/connectors_code/connectors/main.py
  url: null
  file_path: connectors/main.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/environment/connectors/main.py
  workspace_path: null
  environment_path: connectors/main.py
  description: main.py
  format: python
  required: true
  read_only: true
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/connectors_code/connectors/metrics.py:
        directive: null
        original_path: andesite/connectors_code/connectors/metrics.py
        function_name: null
        resolved_path: andesite/connectors_code/connectors/metrics.py
  url: null
  file_path: connectors/metrics.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/environment/connectors/metrics.py
  workspace_path: null
  environment_path: connectors/metrics.py
  description: metrics.py defines the connector metrics interfaces that the connector
    must use
  format: python
  required: true
  read_only: true
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/connectors_code/connectors/parse_alert_configs.py:
        directive: null
        original_path: andesite/connectors_code/connectors/parse_alert_configs.py
        function_name: null
        resolved_path: andesite/connectors_code/connectors/parse_alert_configs.py
  url: null
  file_path: connectors/parse_alert_configs.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/environment/connectors/parse_alert_configs.py
  workspace_path: null
  environment_path: connectors/parse_alert_configs.py
  description: parse_alert_configs.py defines parsing functions that the connector
    may use
  format: python
  required: true
  read_only: true
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/connectors_code/connectors/query_instance.py:
        directive: null
        original_path: andesite/connectors_code/connectors/query_instance.py
        function_name: null
        resolved_path: andesite/connectors_code/connectors/query_instance.py
  url: null
  file_path: connectors/query_instance.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/environment/connectors/query_instance.py
  workspace_path: null
  environment_path: connectors/query_instance.py
  description: 'query_instance.py defines the query instance that the connector needs
    to use '
  format: python
  required: true
  read_only: true
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/connectors_code/connectors/query_target_options.py:
        directive: null
        original_path: andesite/connectors_code/connectors/query_target_options.py
        function_name: null
        resolved_path: andesite/connectors_code/connectors/query_target_options.py
  url: null
  file_path: connectors/query_target_options.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/environment/connectors/query_target_options.py
  workspace_path: null
  environment_path: connectors/query_target_options.py
  description: query_target_options.py defines the connector query_target_options
    interfaces that the connector must use
  format: python
  required: true
  read_only: true
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/connectors_code/connectors/registry.py:
        directive: null
        original_path: andesite/connectors_code/connectors/registry.py
        function_name: null
        resolved_path: andesite/connectors_code/connectors/registry.py
  url: null
  file_path: connectors/registry.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/environment/connectors/registry.py
  workspace_path: null
  environment_path: connectors/registry.py
  description: registry.py defines the connector registry and respective interfaces
    that the connector must adhere to
  format: python
  required: true
  read_only: true
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/connectors_code/connectors/tools.py:
        directive: null
        original_path: andesite/connectors_code/connectors/tools.py
        function_name: null
        resolved_path: andesite/connectors_code/connectors/tools.py
  url: null
  file_path: connectors/tools.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/environment/connectors/tools.py
  workspace_path: null
  environment_path: connectors/tools.py
  description: tools.py defines the interface of the tools the connector must implement
    and define
  format: python
  required: true
  read_only: true
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/common_code/common/base/collection_manager.py:
        directive: null
        original_path: andesite/common_code/common/base/collection_manager.py
        function_name: null
        resolved_path: andesite/common_code/common/base/collection_manager.py
  url: null
  file_path: common/base/collection_manager.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/environment/common/base/collection_manager.py
  workspace_path: null
  environment_path: common/base/collection_manager.py
  description: collection_manager.py provides an abstract base class for MongoDB collection
    management with singleton pattern implementation and asynchronous initialization
    interface
  format: python
  required: true
  read_only: true
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/common_code/common/clients/mongodb_client.py:
        directive: null
        original_path: andesite/common_code/common/clients/mongodb_client.py
        function_name: null
        resolved_path: andesite/common_code/common/clients/mongodb_client.py
  url: null
  file_path: common/clients/mongodb_client.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/environment/common/clients/mongodb_client.py
  workspace_path: null
  environment_path: common/clients/mongodb_client.py
  description: common/clients/mongodb_client.py
  format: python
  required: true
  read_only: true
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/common_code/common/jsonlogging/jsonlogger.py:
        directive: null
        original_path: andesite/common_code/common/jsonlogging/jsonlogger.py
        function_name: null
        resolved_path: andesite/common_code/common/jsonlogging/jsonlogger.py
  url: null
  file_path: common/jsonlogging/jsonlogger.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/environment/common/jsonlogging/jsonlogger.py
  workspace_path: null
  environment_path: common/jsonlogging/jsonlogger.py
  description: jsonlogger.py provides structured JSON logging functionality with context
    tracking and formatting for API requests
  format: python
  required: true
  read_only: true
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/common_code/common/managers/dataset_descriptions/dataset_description_manager.py:
        directive: null
        original_path: andesite/common_code/common/managers/dataset_descriptions/dataset_description_manager.py
        function_name: null
        resolved_path: andesite/common_code/common/managers/dataset_descriptions/dataset_description_manager.py
  url: null
  file_path: common/managers/dataset_descriptions/dataset_description_manager.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/environment/common/managers/dataset_descriptions/dataset_description_manager.py
  workspace_path: null
  environment_path: common/managers/dataset_descriptions/dataset_description_manager.py
  description: dataset_description_manager.py implements MongoDB-based storage and
    retrieval of dataset metadata with async support and telemetry
  format: python
  required: true
  read_only: true
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/common_code/common/managers/dataset_descriptions/dataset_description_model.py:
        directive: null
        original_path: andesite/common_code/common/managers/dataset_descriptions/dataset_description_model.py
        function_name: null
        resolved_path: andesite/common_code/common/managers/dataset_descriptions/dataset_description_model.py
  url: null
  file_path: common/managers/dataset_descriptions/dataset_description_model.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/environment/common/managers/dataset_descriptions/dataset_description_model.py
  workspace_path: null
  environment_path: common/managers/dataset_descriptions/dataset_description_model.py
  description: dataset_description_model.py defines the Pydantic data model for dataset
    metadata with MongoDB serialization support
  format: python
  required: true
  read_only: true
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/common_code/common/managers/dataset_structures/dataset_structure_model.py:
        directive: null
        original_path: andesite/common_code/common/managers/dataset_structures/dataset_structure_model.py
        function_name: null
        resolved_path: andesite/common_code/common/managers/dataset_structures/dataset_structure_model.py
  url: null
  file_path: common/managers/dataset_structures/dataset_structure_model.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/environment/common/managers/dataset_structures/dataset_structure_model.py
  workspace_path: null
  environment_path: common/managers/dataset_structures/dataset_structure_model.py
  description: dataset_structure_model.py defines the Pydantic data model for dataset
    schemas with flexible attribute storage
  format: python
  required: true
  read_only: true
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/common_code/common/managers/enterprise_technique/enterprise_technique_manager.py:
        directive: null
        original_path: andesite/common_code/common/managers/enterprise_technique/enterprise_technique_manager.py
        function_name: null
        resolved_path: andesite/common_code/common/managers/enterprise_technique/enterprise_technique_manager.py
  url: null
  file_path: common/managers/enterprise_technique/enterprise_technique_manager.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/environment/common/managers/enterprise_technique/enterprise_technique_manager.py
  workspace_path: null
  environment_path: common/managers/enterprise_technique/enterprise_technique_manager.py
  description: enterprise_technique_manager.py implements MongoDB storage and retrieval
    for MITRE ATT&CK Enterprise techniques with prioritization support
  format: python
  required: true
  read_only: true
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/common_code/common/managers/prioritization_rules/prioritization_rules_manager.py:
        directive: null
        original_path: andesite/common_code/common/managers/prioritization_rules/prioritization_rules_manager.py
        function_name: null
        resolved_path: andesite/common_code/common/managers/prioritization_rules/prioritization_rules_manager.py
  url: null
  file_path: common/managers/prioritization_rules/prioritization_rules_manager.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/environment/common/managers/prioritization_rules/prioritization_rules_manager.py
  workspace_path: null
  environment_path: common/managers/prioritization_rules/prioritization_rules_manager.py
  description: prioritization_rules_manager.py implements MongoDB persistence for
    analysis prioritization rules with async operations and telemetry tracing
  format: python
  required: true
  read_only: true
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/common_code/common/managers/prioritization_rules/prioritization_rules_model.py:
        directive: null
        original_path: andesite/common_code/common/managers/prioritization_rules/prioritization_rules_model.py
        function_name: null
        resolved_path: andesite/common_code/common/managers/prioritization_rules/prioritization_rules_model.py
  url: null
  file_path: common/managers/prioritization_rules/prioritization_rules_model.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/environment/common/managers/prioritization_rules/prioritization_rules_model.py
  workspace_path: null
  environment_path: common/managers/prioritization_rules/prioritization_rules_model.py
  description: prioritization_rules_model.py defines the Pydantic data model for regex-based
    analysis prioritization with data validation
  format: python
  required: true
  read_only: true
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/common_code/common/managers/user/user_model.py:
        directive: null
        original_path: andesite/common_code/common/managers/user/user_model.py
        function_name: null
        resolved_path: andesite/common_code/common/managers/user/user_model.py
  url: null
  file_path: common/managers/user/user_model.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/environment/common/managers/user/user_model.py
  workspace_path: null
  environment_path: common/managers/user/user_model.py
  description: user_model.py defines the Pydantic model for user data with secure
    token encryption/decryption capabilities
  format: python
  required: true
  read_only: true
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/common_code/common/managers/user/user_manager.py:
        directive: null
        original_path: andesite/common_code/common/managers/user/user_manager.py
        function_name: null
        resolved_path: andesite/common_code/common/managers/user/user_manager.py
  url: null
  file_path: common/managers/user/user_manager.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/environment/common/managers/user/user_manager.py
  workspace_path: null
  environment_path: common/managers/user/user_manager.py
  description: common/managers/user/user_manager.py
  format: python
  required: true
  read_only: true
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/common_code/common/models/alerts.py:
        directive: null
        original_path: andesite/common_code/common/models/alerts.py
        function_name: null
        resolved_path: andesite/common_code/common/models/alerts.py
  url: null
  file_path: common/models/alerts.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/environment/common/models/alerts.py
  workspace_path: null
  environment_path: common/models/alerts.py
  description: common/models/alerts.py
  format: python
  required: true
  read_only: true
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/common_code/common/models/connector_id_enum.py:
        directive: null
        original_path: andesite/common_code/common/models/connector_id_enum.py
        function_name: null
        resolved_path: andesite/common_code/common/models/connector_id_enum.py
  url: null
  file_path: common/models/connector_id_enum.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/environment/common/models/connector_id_enum.py
  workspace_path: null
  environment_path: common/models/connector_id_enum.py
  description: common/models/connector_id_enum.py
  format: python
  required: true
  read_only: false
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/common_code/common/models/cron_config.py:
        directive: null
        original_path: andesite/common_code/common/models/cron_config.py
        function_name: null
        resolved_path: andesite/common_code/common/models/cron_config.py
  url: null
  file_path: common/models/cron_config.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/environment/common/models/cron_config.py
  workspace_path: null
  environment_path: common/models/cron_config.py
  description: cron_config.py defines a Pydantic model for cron expressions with validation
    and field parsing
  format: python
  required: true
  read_only: true
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/common_code/common/models/secret.py:
        directive: null
        original_path: andesite/common_code/common/models/secret.py
        function_name: null
        resolved_path: andesite/common_code/common/models/secret.py
  url: null
  file_path: common/models/secret.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/environment/common/models/secret.py
  workspace_path: null
  environment_path: common/models/secret.py
  description: secret.py
  format: python
  required: true
  read_only: true
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/common_code/common/models/tool.py:
        directive: null
        original_path: andesite/common_code/common/models/tool.py
        function_name: null
        resolved_path: andesite/common_code/common/models/tool.py
  url: null
  file_path: common/models/tool.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/environment/common/models/tool.py
  workspace_path: null
  environment_path: common/models/tool.py
  description: tool.py implements a framework for executable tools with input validation,
    telemetry and standardized result formatting
  format: python
  required: true
  read_only: true
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/common_code/common/models/metadata.py:
        directive: null
        original_path: andesite/common_code/common/models/metadata.py
        function_name: null
        resolved_path: andesite/common_code/common/models/metadata.py
  url: null
  file_path: common/models/metadata.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/environment/common/models/metadata.py
  workspace_path: null
  environment_path: common/models/metadata.py
  description: metadata.py used by tool.py
  format: python
  required: true
  read_only: true
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/common_code/common/models/mitre.py:
        directive: null
        original_path: andesite/common_code/common/models/mitre.py
        function_name: null
        resolved_path: andesite/common_code/common/models/mitre.py
  url: null
  file_path: common/models/mitre.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/environment/common/models/mitre.py
  workspace_path: null
  environment_path: common/models/mitre.py
  description: mitre.py
  format: python
  required: true
  read_only: true
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/common_code/common/opentelemetry/context.py:
        directive: null
        original_path: andesite/common_code/common/opentelemetry/context.py
        function_name: null
        resolved_path: andesite/common_code/common/opentelemetry/context.py
  url: null
  file_path: common/opentelemetry/context.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/environment/common/opentelemetry/context.py
  workspace_path: null
  environment_path: common/opentelemetry/context.py
  description: common/opentelemetry/context.py
  format: python
  required: true
  read_only: true
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/common_code/common/utils/fallback_none.py:
        directive: null
        original_path: andesite/common_code/common/utils/fallback_none.py
        function_name: null
        resolved_path: andesite/common_code/common/utils/fallback_none.py
  url: null
  file_path: common/utils/fallback_none.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/environment/common/utils/fallback_none.py
  workspace_path: null
  environment_path: common/utils/fallback_none.py
  description: fallback_none.py provides a utility function for graceful Pydantic
    model validation with None fallback
  format: python
  required: true
  read_only: true
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/common_code/common/utils/flatten_dict.py:
        directive: null
        original_path: andesite/common_code/common/utils/flatten_dict.py
        function_name: null
        resolved_path: andesite/common_code/common/utils/flatten_dict.py
  url: null
  file_path: common/utils/flatten_dict.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/environment/common/utils/flatten_dict.py
  workspace_path: null
  environment_path: common/utils/flatten_dict.py
  description: flatten_dict.py
  format: python
  required: true
  read_only: true
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/common_code/common/utils/context.py:
        directive: null
        original_path: andesite/common_code/common/utils/context.py
        function_name: null
        resolved_path: andesite/common_code/common/utils/context.py
  url: null
  file_path: common/utils/context.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/environment/common/utils/context.py
  workspace_path: null
  environment_path: common/utils/context.py
  description: context.py
  format: python
  required: true
  read_only: true
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/common_code/common/utils/pydantic_helper.py:
        directive: null
        original_path: andesite/common_code/common/utils/pydantic_helper.py
        function_name: null
        resolved_path: andesite/common_code/common/utils/pydantic_helper.py
  url: null
  file_path: common/utils/pydantic_helper.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/environment/common/utils/pydantic_helper.py
  workspace_path: null
  environment_path: common/utils/pydantic_helper.py
  description: pydantic_helper.py
  format: python
  required: true
  read_only: true
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files:
      andesite/common_code/common/utils/timer.py:
        directive: null
        original_path: andesite/common_code/common/utils/timer.py
        function_name: null
        resolved_path: andesite/common_code/common/utils/timer.py
  url: null
  file_path: common/utils/timer.py
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/environment/common/utils/timer.py
  workspace_path: null
  environment_path: common/utils/timer.py
  description: timer.py
  format: python
  required: true
  read_only: true
- provenance:
    source_file: domains/case_management/jira/jira.yaml
    domain: case_management
    manifest: jira
    referenced_files:
      domains/case_management/jira/jira.svg:
        directive: null
        original_path: domains/case_management/jira/jira.svg
        function_name: null
        resolved_path: domains/case_management/jira/jira.svg
  url: null
  file_path: connectors/jira/connector/jira.svg
  absolute_path: /tmp/zerg/agent_workspace_oo7otk7t/environment/connectors/jira/connector/jira.svg
  workspace_path: null
  environment_path: connectors/jira/connector/jira.svg
  description: JIRA SVG logo
  format: svg
  required: true
  read_only: true
configs:
- provenance:
    source_file: suite.yaml
    domain: null
    manifest: null
    referenced_files: {}
  name: considerations
  value:
  - you are a top-tier data connector engineer, with an eye for detail and architecture
    - plus you're nice and easy to work with
  - ensure that you adhere to the connector architecture as defined in the connectors
    interface and provided connector examples
  - do not fake functionality, do not pass back simulated values - all functionality
    must work in the context of the connector specs, specifications and requirements
  - note that connectors may call to common code, this is not available - when this
    is the case, simply stub this out as needed
  - if an import failes, consider whether it's common code or a missing package -
    if missing package, install the package do not shim what are obvious dependencies
  - note that code in the connectors framework, with the exception of the enums, is
    read only and cannot be edited, modified or otherwise and must be used as is
  - if you find yourself hitting the same error, or issue, please consider 2-3 alternative
    approaches and choose one of them to try next
  - __init__.py files should not contain code, but they should be created as empty
    files as needed
  description: "Various considerations for the generation of connectors with regards\
    \ to the connector framework \nas provided - please keep these strongly in mind\n"
- provenance:
    source_file: domains/case_management/jira/jira.yaml
    domain: case_management
    manifest: jira
    referenced_files: {}
  name: jira_url
  value: []
  description: The base URL of the JIRA instance, note this should be included as
    url in JIRAConnectorConfig
- provenance:
    source_file: domains/case_management/jira/jira.yaml
    domain: case_management
    manifest: jira
    referenced_files: {}
  name: jira_api_token
  value: []
  description: "API Token for authenticating with JIRA, stored as a StorableSecret\
    \ in JIRAConnectorConfig.api_key field; \nThis will be encrypted using StorableSecret\
    \ and accessed via the secrets mechanism\n"
- provenance:
    source_file: domains/case_management/jira/jira.yaml
    domain: case_management
    manifest: jira
    referenced_files: {}
  name: jira_email
  value: []
  description: Email address for authenticating with JIRA, note this should be included
    as email in JIRAConnectorConfig
- provenance:
    source_file: domains/case_management/jira/jira.yaml
    domain: case_management
    manifest: jira
    referenced_files: {}
  name: jira_api_request_timeout
  value: 30
  description: Request timeout in seconds
- provenance:
    source_file: domains/case_management/jira/jira.yaml
    domain: case_management
    manifest: jira
    referenced_files: {}
  name: jira_api_max_retries
  value: 3
  description: Number of times to retry API requests upon failure
- provenance:
    source_file: domains/case_management/jira/jira.yaml
    domain: case_management
    manifest: jira
    referenced_files: {}
  name: connector_module
  value: jira
  description: name of connector module
- provenance:
    source_file: domains/case_management/jira/jira.yaml
    domain: case_management
    manifest: jira
    referenced_files: {}
  name: connector_name
  value: JIRA
  description: name of connector
- provenance:
    source_file: domains/case_management/jira/jira.yaml
    domain: case_management
    manifest: jira
    referenced_files: {}
  name: selectors
  value:
    project_keys:
      target: project
      __source_file__: domains/case_management/jira/jira.yaml
    __source_file__: domains/case_management/jira/jira.yaml
  description: supported data connector selectors for use with quer_target_options
- provenance:
    source_file: domains/case_management/jira/jira.yaml
    domain: case_management
    manifest: jira
    referenced_files: {}
  name: expected_tools
  value:
  - get_jira_projects
  - get_jira_issues
  description: supported tools as expected by the data connector generation
- provenance:
    source_file: domains/case_management/jira/jira.yaml
    domain: case_management
    manifest: jira
    referenced_files: {}
  name: additional considerations
  value:
  - JIRAConnectorConfig should dervice from ConnectorConfig, this is not a connector
    of type AlertProviderConnectorConfig config
  - authentication should not be a tool, tools should handle authentication when used
    (so should not be explicitly exposed)
  - utilize the query target options to determine which projects are valid for the
    target, and then use the target to select which projects to actually pull data
    from for the respective tools as shown in the unit tests
  description: "Additional considerations for the generation of specifically the JIRA\
    \ connector \nwith regards to the connector framework as provided - please keep\
    \ these strongly in mind\n"
metadata:
  agent_uuid: a4b7e395cab44dcb9dc17c6a202bb235
  status: IDLE
  max_depth: 500
  export_timestamp: '2025-08-27 18:23:16.279096'
  environment_type: FSEnvironment
  environment_name: fs_environment
  environment_root: /tmp/zerg/agent_workspace_oo7otk7t/environment
  workspace_path: ''
  workspace_files_count: 0
